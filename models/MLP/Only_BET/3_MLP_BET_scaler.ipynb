{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6ed48b-d6d9-41be-a784-87fa2e27fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 23:40:23.144693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742424023.163201  239540 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742424023.168791  239540 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-19 23:40:23.187415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path_to_data_notebook = Path.cwd().parent.parent.parent / \"Data\" / \"1_Preprocesed_data.ipynb\"\n",
    "%run {path_to_data_notebook}\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import datetime \n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3468d7fa-695f-45c3-862a-30711a78c900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pc/moje/python_projects/adsorbents_isotherms/Data/all_data.csv\n",
      "------------------------------- Preprocessing_data start -------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1011 entries, 0 to 1010\n",
      "Data columns (total 26 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Article_name                    1011 non-null   object \n",
      " 1   Figure_number                   1011 non-null   object \n",
      " 2   Sample_name                     1011 non-null   object \n",
      " 3   Total_surface_area[m2/g]        928 non-null    float64\n",
      " 4   Total_pore_volume[cm3/g]        778 non-null    float64\n",
      " 5   Micropore_volume[cm3/g]         730 non-null    float64\n",
      " 6   Mesopore_volume[cm3/g]          21 non-null     float64\n",
      " 7   Average_pore_diameter[nm]       121 non-null    float64\n",
      " 8   Impregnation_ratio[agent/char]  20 non-null     float64\n",
      " 9   Activation_type                 33 non-null     object \n",
      " 10  Burn_off[%]                     75 non-null     float64\n",
      " 11  Carbonization_time[h]           210 non-null    float64\n",
      " 12  Carbonization_temperature[stC]  253 non-null    float64\n",
      " 13  Activation_time[h]              509 non-null    float64\n",
      " 14  Activation_temperature[stC]     699 non-null    float64\n",
      " 15  Modification_agent              9 non-null      object \n",
      " 16  Activation_agent                920 non-null    object \n",
      " 17  Material_type                   981 non-null    object \n",
      " 18  Curve_type                      945 non-null    object \n",
      " 19  Y_axis_type                     204 non-null    object \n",
      " 20  axis_minx_maxx_miny_maxy        1011 non-null   object \n",
      " 21  DOI                             988 non-null    object \n",
      " 22  PrimaryTitle                    1011 non-null   object \n",
      " 23  isotherm_X                      1011 non-null   object \n",
      " 24  isotherm_Y                      1011 non-null   object \n",
      " 25  isotherm_X_Y                    1011 non-null   object \n",
      "dtypes: float64(11), object(15)\n",
      "memory usage: 205.5+ KB\n",
      "None\n",
      "return x range from 0.001\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 980 entries, 0 to 1010\n",
      "Data columns (total 28 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Article_name                    980 non-null    object \n",
      " 1   Figure_number                   980 non-null    object \n",
      " 2   Sample_name                     980 non-null    object \n",
      " 3   Total_surface_area[m2/g]        897 non-null    float64\n",
      " 4   Total_pore_volume[cm3/g]        749 non-null    float64\n",
      " 5   Micropore_volume[cm3/g]         719 non-null    float64\n",
      " 6   Mesopore_volume[cm3/g]          21 non-null     float64\n",
      " 7   Average_pore_diameter[nm]       121 non-null    float64\n",
      " 8   Impregnation_ratio[agent/char]  20 non-null     float64\n",
      " 9   Activation_type                 33 non-null     object \n",
      " 10  Burn_off[%]                     75 non-null     float64\n",
      " 11  Carbonization_time[h]           210 non-null    float64\n",
      " 12  Carbonization_temperature[stC]  253 non-null    float64\n",
      " 13  Activation_time[h]              497 non-null    float64\n",
      " 14  Activation_temperature[stC]     687 non-null    float64\n",
      " 15  Modification_agent              9 non-null      object \n",
      " 16  Activation_agent                904 non-null    object \n",
      " 17  Material_type                   953 non-null    object \n",
      " 18  Curve_type                      917 non-null    object \n",
      " 19  Y_axis_type                     200 non-null    object \n",
      " 20  axis_minx_maxx_miny_maxy        980 non-null    object \n",
      " 21  DOI                             957 non-null    object \n",
      " 22  PrimaryTitle                    980 non-null    object \n",
      " 23  isotherm_X                      980 non-null    object \n",
      " 24  isotherm_Y                      980 non-null    object \n",
      " 25  isotherm_X_Y                    980 non-null    object \n",
      " 26  processed_isotherm_X_Y          980 non-null    object \n",
      " 27  processed_flatten_isotherm_X_Y  980 non-null    object \n",
      "dtypes: float64(11), object(17)\n",
      "memory usage: 222.0+ KB\n",
      "None\n",
      "------------------------------- Preprocessing_data end -------------------------------\n",
      "X_train size = 879\n",
      "y_train size = 879\n",
      "X_test size = 18\n",
      "y_test size = 18\n"
     ]
    }
   ],
   "source": [
    "size = 35\n",
    "x_range_to_cut = 0.001\n",
    "df = get_whole_preprocessed_dataframe(size, x_range_to_cut)\n",
    "# choosen property for y:\n",
    "choosen_property_1 = \"Total_surface_area[m2/g]\"\n",
    "\n",
    "# ------------------------------- scaler\n",
    "output_scaler = StandardScaler()\n",
    "df[choosen_property_1] = output_scaler.fit_transform(df[[choosen_property_1]])\n",
    "# ------------------------------- scaler\n",
    "\n",
    "df_with_data = df[df[choosen_property_1].notna()]    # get data if property are present\n",
    "df_without_data = df[df[choosen_property_1].isna()]    # get data if property arent present\n",
    "\n",
    "X = df_with_data['processed_flatten_isotherm_X_Y'] # x = 'processed_flatten_isotherm_X_Y'\n",
    "y = df_with_data # y - temporary all columns for prediction inspection, in next steps we extract only choosen property\n",
    "\n",
    "X_train, X_test, y_train_nested, y_test_nested, = train_test_split(X, y, test_size=0.02, random_state=42) #random_state=42\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "y_train = y_train_nested[choosen_property_1].to_numpy()\n",
    "y_test = y_test_nested[choosen_property_1].to_numpy() \n",
    "\n",
    "\n",
    "scaler = StandardScaler() # only for x data\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "print(f'X_train size = {len(X_train)}')\n",
    "print(f'y_train size = {len(X_train)}')\n",
    "print(f'X_test size = {len(X_test)}')\n",
    "print(f'y_test size = {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc08518e-ad6d-4f49-a1b0-bfefee7a8ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_without size = 83\n",
      "y_without size = 83\n"
     ]
    }
   ],
   "source": [
    "X_without = df_without_data['processed_flatten_isotherm_X_Y'].tolist()\n",
    "X_without = scaler.transform(X_without) \n",
    "y_without = df_without_data[choosen_property_1].to_numpy()\n",
    "print(f'X_without size = {len(X_without)}')\n",
    "print(f'y_without size = {len(y_without)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd92911-68be-4035-b12a-f17a72bfd493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a302be5b-8212-4917-90bb-d05bce0a6178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c20d84-084c-4dca-9388-5655622cbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time(transcription_time):\n",
    "    timedelta_obj = datetime.timedelta(seconds=int(transcription_time))\n",
    "    return str(timedelta_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2e7847-6931-405a-8240-2ee3bdee18b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742424025.118143  239540 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9282 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742424026.199107  239591 service.cc:148] XLA service 0x7ebd48009430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742424026.199133  239591 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-03-19 23:40:26.226068: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742424026.348791  239591 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1742424026.871741  239591 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 3s - 105ms/step - loss: 0.2971 - mae: 0.2971 - mse: 0.2702 - val_loss: 0.1701 - val_mae: 0.1701 - val_mse: 0.0537\n",
      "Epoch 2/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1605 - mae: 0.1605 - mse: 0.0612 - val_loss: 0.1454 - val_mae: 0.1454 - val_mse: 0.0388\n",
      "Epoch 3/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1486 - mae: 0.1486 - mse: 0.0518 - val_loss: 0.1427 - val_mae: 0.1427 - val_mse: 0.0436\n",
      "Epoch 4/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1351 - mae: 0.1351 - mse: 0.0445 - val_loss: 0.1184 - val_mae: 0.1184 - val_mse: 0.0336\n",
      "Epoch 5/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1317 - mae: 0.1317 - mse: 0.0428 - val_loss: 0.1332 - val_mae: 0.1332 - val_mse: 0.0407\n",
      "Epoch 6/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1262 - mae: 0.1262 - mse: 0.0405 - val_loss: 0.1337 - val_mae: 0.1337 - val_mse: 0.0414\n",
      "Epoch 7/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1267 - mae: 0.1267 - mse: 0.0407 - val_loss: 0.1495 - val_mae: 0.1495 - val_mse: 0.0475\n",
      "Epoch 8/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1251 - mae: 0.1251 - mse: 0.0380 - val_loss: 0.1325 - val_mae: 0.1325 - val_mse: 0.0357\n",
      "Epoch 9/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1175 - mae: 0.1175 - mse: 0.0358 - val_loss: 0.1551 - val_mae: 0.1551 - val_mse: 0.0490\n",
      "Epoch 10/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1262 - mae: 0.1262 - mse: 0.0375 - val_loss: 0.1280 - val_mae: 0.1280 - val_mse: 0.0377\n",
      "Epoch 11/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1229 - mae: 0.1229 - mse: 0.0369 - val_loss: 0.1409 - val_mae: 0.1409 - val_mse: 0.0409\n",
      "Epoch 12/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1195 - mae: 0.1195 - mse: 0.0362 - val_loss: 0.1419 - val_mae: 0.1419 - val_mse: 0.0475\n",
      "Epoch 13/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1108 - mae: 0.1108 - mse: 0.0323 - val_loss: 0.1384 - val_mae: 0.1384 - val_mse: 0.0408\n",
      "Epoch 14/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1109 - mae: 0.1109 - mse: 0.0320 - val_loss: 0.1305 - val_mae: 0.1305 - val_mse: 0.0383\n",
      "Epoch 15/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1118 - mae: 0.1118 - mse: 0.0318 - val_loss: 0.1264 - val_mae: 0.1264 - val_mse: 0.0397\n",
      "Epoch 16/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1139 - mae: 0.1139 - mse: 0.0326 - val_loss: 0.1408 - val_mae: 0.1408 - val_mse: 0.0411\n",
      "Epoch 17/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1078 - mae: 0.1078 - mse: 0.0296 - val_loss: 0.1441 - val_mae: 0.1441 - val_mse: 0.0459\n",
      "Epoch 18/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1148 - mae: 0.1148 - mse: 0.0343 - val_loss: 0.1269 - val_mae: 0.1269 - val_mse: 0.0400\n",
      "Epoch 19/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1071 - mae: 0.1071 - mse: 0.0295 - val_loss: 0.1412 - val_mae: 0.1412 - val_mse: 0.0434\n",
      "Epoch 20/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1012 - mae: 0.1012 - mse: 0.0298 - val_loss: 0.1355 - val_mae: 0.1355 - val_mse: 0.0423\n",
      "Epoch 21/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1019 - mae: 0.1019 - mse: 0.0301 - val_loss: 0.1232 - val_mae: 0.1232 - val_mse: 0.0350\n",
      "Epoch 22/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1102 - mae: 0.1102 - mse: 0.0302 - val_loss: 0.1334 - val_mae: 0.1334 - val_mse: 0.0409\n",
      "Epoch 23/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1001 - mae: 0.1001 - mse: 0.0281 - val_loss: 0.1313 - val_mae: 0.1313 - val_mse: 0.0366\n",
      "Epoch 24/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1056 - mae: 0.1056 - mse: 0.0283 - val_loss: 0.1264 - val_mae: 0.1264 - val_mse: 0.0371\n",
      "Epoch 25/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0979 - mae: 0.0979 - mse: 0.0278 - val_loss: 0.1387 - val_mae: 0.1387 - val_mse: 0.0444\n",
      "Epoch 26/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0943 - mae: 0.0943 - mse: 0.0263 - val_loss: 0.1361 - val_mae: 0.1361 - val_mse: 0.0425\n",
      "Epoch 27/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0917 - mae: 0.0917 - mse: 0.0257 - val_loss: 0.1248 - val_mae: 0.1248 - val_mse: 0.0363\n",
      "Epoch 28/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0999 - mae: 0.0999 - mse: 0.0260 - val_loss: 0.1356 - val_mae: 0.1356 - val_mse: 0.0430\n",
      "Epoch 29/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1041 - mae: 0.1041 - mse: 0.0292 - val_loss: 0.1314 - val_mae: 0.1314 - val_mse: 0.0415\n",
      "Epoch 30/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0972 - mae: 0.0972 - mse: 0.0273 - val_loss: 0.1420 - val_mae: 0.1420 - val_mse: 0.0464\n",
      "Epoch 31/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1024 - mae: 0.1024 - mse: 0.0285 - val_loss: 0.1469 - val_mae: 0.1469 - val_mse: 0.0465\n",
      "Epoch 32/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.1007 - mae: 0.1007 - mse: 0.0278 - val_loss: 0.1236 - val_mae: 0.1236 - val_mse: 0.0339\n",
      "Epoch 33/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0922 - mae: 0.0922 - mse: 0.0255 - val_loss: 0.1485 - val_mae: 0.1485 - val_mse: 0.0476\n",
      "Epoch 34/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0921 - mae: 0.0921 - mse: 0.0250 - val_loss: 0.1290 - val_mae: 0.1290 - val_mse: 0.0408\n",
      "Epoch 35/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0938 - mae: 0.0938 - mse: 0.0257 - val_loss: 0.1356 - val_mae: 0.1356 - val_mse: 0.0440\n",
      "Epoch 36/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0884 - mae: 0.0884 - mse: 0.0240 - val_loss: 0.1317 - val_mae: 0.1317 - val_mse: 0.0390\n",
      "Epoch 37/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0952 - mae: 0.0952 - mse: 0.0275 - val_loss: 0.1263 - val_mae: 0.1263 - val_mse: 0.0359\n",
      "Epoch 38/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0878 - mae: 0.0878 - mse: 0.0239 - val_loss: 0.1359 - val_mae: 0.1359 - val_mse: 0.0425\n",
      "Epoch 39/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0870 - mae: 0.0870 - mse: 0.0241 - val_loss: 0.1498 - val_mae: 0.1498 - val_mse: 0.0488\n",
      "Epoch 40/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0969 - mae: 0.0969 - mse: 0.0269 - val_loss: 0.1283 - val_mae: 0.1283 - val_mse: 0.0392\n",
      "Epoch 41/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0905 - mae: 0.0905 - mse: 0.0250 - val_loss: 0.1458 - val_mae: 0.1458 - val_mse: 0.0445\n",
      "Epoch 42/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0887 - mae: 0.0887 - mse: 0.0239 - val_loss: 0.1406 - val_mae: 0.1406 - val_mse: 0.0433\n",
      "Epoch 43/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0889 - mae: 0.0889 - mse: 0.0227 - val_loss: 0.1379 - val_mae: 0.1379 - val_mse: 0.0431\n",
      "Epoch 44/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0889 - mae: 0.0889 - mse: 0.0237 - val_loss: 0.1378 - val_mae: 0.1378 - val_mse: 0.0459\n",
      "Epoch 45/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0839 - mae: 0.0839 - mse: 0.0216 - val_loss: 0.1337 - val_mae: 0.1337 - val_mse: 0.0402\n",
      "Epoch 46/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0814 - mae: 0.0814 - mse: 0.0216 - val_loss: 0.1470 - val_mae: 0.1470 - val_mse: 0.0450\n",
      "Epoch 47/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0963 - mae: 0.0963 - mse: 0.0269 - val_loss: 0.1282 - val_mae: 0.1282 - val_mse: 0.0409\n",
      "Epoch 48/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0835 - mae: 0.0835 - mse: 0.0230 - val_loss: 0.1261 - val_mae: 0.1261 - val_mse: 0.0385\n",
      "Epoch 49/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0776 - mae: 0.0776 - mse: 0.0214 - val_loss: 0.1293 - val_mae: 0.1293 - val_mse: 0.0392\n",
      "Epoch 50/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0901 - mae: 0.0901 - mse: 0.0229 - val_loss: 0.1426 - val_mae: 0.1426 - val_mse: 0.0458\n",
      "Epoch 51/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0810 - mae: 0.0810 - mse: 0.0212 - val_loss: 0.1271 - val_mae: 0.1271 - val_mse: 0.0390\n",
      "Epoch 52/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0818 - mae: 0.0818 - mse: 0.0212 - val_loss: 0.1335 - val_mae: 0.1335 - val_mse: 0.0409\n",
      "Epoch 53/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0837 - mae: 0.0837 - mse: 0.0211 - val_loss: 0.1339 - val_mae: 0.1339 - val_mse: 0.0401\n",
      "Epoch 54/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0829 - mae: 0.0829 - mse: 0.0217 - val_loss: 0.1431 - val_mae: 0.1431 - val_mse: 0.0440\n",
      "Epoch 55/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0846 - mae: 0.0846 - mse: 0.0222 - val_loss: 0.1411 - val_mae: 0.1411 - val_mse: 0.0402\n",
      "Epoch 56/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0780 - mae: 0.0780 - mse: 0.0197 - val_loss: 0.1267 - val_mae: 0.1267 - val_mse: 0.0375\n",
      "Epoch 57/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0831 - mae: 0.0831 - mse: 0.0218 - val_loss: 0.1398 - val_mae: 0.1398 - val_mse: 0.0428\n",
      "Epoch 58/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0814 - mae: 0.0814 - mse: 0.0208 - val_loss: 0.1417 - val_mae: 0.1417 - val_mse: 0.0449\n",
      "Epoch 59/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0846 - mae: 0.0846 - mse: 0.0228 - val_loss: 0.1374 - val_mae: 0.1374 - val_mse: 0.0428\n",
      "Epoch 60/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0753 - mae: 0.0753 - mse: 0.0190 - val_loss: 0.1359 - val_mae: 0.1359 - val_mse: 0.0389\n",
      "Epoch 61/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0803 - mae: 0.0803 - mse: 0.0210 - val_loss: 0.1297 - val_mae: 0.1297 - val_mse: 0.0401\n",
      "Epoch 62/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0745 - mae: 0.0745 - mse: 0.0194 - val_loss: 0.1288 - val_mae: 0.1288 - val_mse: 0.0398\n",
      "Epoch 63/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0778 - mae: 0.0778 - mse: 0.0204 - val_loss: 0.1392 - val_mae: 0.1392 - val_mse: 0.0410\n",
      "Epoch 64/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0782 - mae: 0.0782 - mse: 0.0199 - val_loss: 0.1369 - val_mae: 0.1369 - val_mse: 0.0390\n",
      "Epoch 65/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0831 - mae: 0.0831 - mse: 0.0202 - val_loss: 0.1675 - val_mae: 0.1675 - val_mse: 0.0608\n",
      "Epoch 66/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0894 - mae: 0.0894 - mse: 0.0245 - val_loss: 0.1398 - val_mae: 0.1398 - val_mse: 0.0447\n",
      "Epoch 67/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0808 - mae: 0.0808 - mse: 0.0198 - val_loss: 0.1505 - val_mae: 0.1505 - val_mse: 0.0429\n",
      "Epoch 68/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0782 - mae: 0.0782 - mse: 0.0195 - val_loss: 0.1390 - val_mae: 0.1390 - val_mse: 0.0432\n",
      "Epoch 69/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0755 - mae: 0.0755 - mse: 0.0201 - val_loss: 0.1467 - val_mae: 0.1467 - val_mse: 0.0466\n",
      "Epoch 70/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0740 - mae: 0.0740 - mse: 0.0184 - val_loss: 0.1401 - val_mae: 0.1401 - val_mse: 0.0454\n",
      "Epoch 71/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0734 - mae: 0.0734 - mse: 0.0182 - val_loss: 0.1340 - val_mae: 0.1340 - val_mse: 0.0409\n",
      "Epoch 72/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0741 - mae: 0.0741 - mse: 0.0187 - val_loss: 0.1287 - val_mae: 0.1287 - val_mse: 0.0410\n",
      "Epoch 73/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0708 - mae: 0.0708 - mse: 0.0171 - val_loss: 0.1377 - val_mae: 0.1377 - val_mse: 0.0413\n",
      "Epoch 74/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0791 - mae: 0.0791 - mse: 0.0192 - val_loss: 0.1453 - val_mae: 0.1453 - val_mse: 0.0462\n",
      "Epoch 75/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0794 - mae: 0.0794 - mse: 0.0194 - val_loss: 0.1399 - val_mae: 0.1399 - val_mse: 0.0431\n",
      "Epoch 76/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0758 - mae: 0.0758 - mse: 0.0181 - val_loss: 0.1300 - val_mae: 0.1300 - val_mse: 0.0405\n",
      "Epoch 77/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0763 - mae: 0.0763 - mse: 0.0186 - val_loss: 0.1314 - val_mae: 0.1314 - val_mse: 0.0409\n",
      "Epoch 78/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0737 - mae: 0.0737 - mse: 0.0180 - val_loss: 0.1409 - val_mae: 0.1409 - val_mse: 0.0463\n",
      "Epoch 79/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0749 - mae: 0.0749 - mse: 0.0177 - val_loss: 0.1394 - val_mae: 0.1394 - val_mse: 0.0430\n",
      "Epoch 80/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0755 - mae: 0.0755 - mse: 0.0173 - val_loss: 0.1458 - val_mae: 0.1458 - val_mse: 0.0454\n",
      "Epoch 81/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0791 - mae: 0.0791 - mse: 0.0191 - val_loss: 0.1470 - val_mae: 0.1470 - val_mse: 0.0486\n",
      "Epoch 82/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0745 - mae: 0.0745 - mse: 0.0174 - val_loss: 0.1445 - val_mae: 0.1445 - val_mse: 0.0433\n",
      "Epoch 83/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0703 - mae: 0.0703 - mse: 0.0170 - val_loss: 0.1345 - val_mae: 0.1345 - val_mse: 0.0400\n",
      "Epoch 84/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0695 - mae: 0.0695 - mse: 0.0158 - val_loss: 0.1369 - val_mae: 0.1369 - val_mse: 0.0446\n",
      "Epoch 85/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0720 - mae: 0.0720 - mse: 0.0170 - val_loss: 0.1380 - val_mae: 0.1380 - val_mse: 0.0418\n",
      "Epoch 86/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0692 - mae: 0.0692 - mse: 0.0163 - val_loss: 0.1379 - val_mae: 0.1379 - val_mse: 0.0424\n",
      "Epoch 87/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0682 - mae: 0.0682 - mse: 0.0162 - val_loss: 0.1324 - val_mae: 0.1324 - val_mse: 0.0431\n",
      "Epoch 88/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0661 - mae: 0.0661 - mse: 0.0157 - val_loss: 0.1324 - val_mae: 0.1324 - val_mse: 0.0412\n",
      "Epoch 89/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0629 - mae: 0.0629 - mse: 0.0151 - val_loss: 0.1435 - val_mae: 0.1435 - val_mse: 0.0449\n",
      "Epoch 90/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0642 - mae: 0.0642 - mse: 0.0149 - val_loss: 0.1332 - val_mae: 0.1332 - val_mse: 0.0445\n",
      "Epoch 91/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0713 - mae: 0.0713 - mse: 0.0165 - val_loss: 0.1408 - val_mae: 0.1408 - val_mse: 0.0491\n",
      "Epoch 92/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0643 - mae: 0.0643 - mse: 0.0141 - val_loss: 0.1454 - val_mae: 0.1454 - val_mse: 0.0488\n",
      "Epoch 93/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0688 - mae: 0.0688 - mse: 0.0154 - val_loss: 0.1421 - val_mae: 0.1421 - val_mse: 0.0479\n",
      "Epoch 94/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0665 - mae: 0.0665 - mse: 0.0158 - val_loss: 0.1400 - val_mae: 0.1400 - val_mse: 0.0445\n",
      "Epoch 95/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0651 - mae: 0.0651 - mse: 0.0145 - val_loss: 0.1401 - val_mae: 0.1401 - val_mse: 0.0463\n",
      "Epoch 96/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0655 - mae: 0.0655 - mse: 0.0154 - val_loss: 0.1398 - val_mae: 0.1398 - val_mse: 0.0441\n",
      "Epoch 97/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0724 - mae: 0.0724 - mse: 0.0157 - val_loss: 0.1423 - val_mae: 0.1423 - val_mse: 0.0443\n",
      "Epoch 98/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0684 - mae: 0.0684 - mse: 0.0149 - val_loss: 0.1481 - val_mae: 0.1481 - val_mse: 0.0509\n",
      "Epoch 99/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0716 - mae: 0.0716 - mse: 0.0160 - val_loss: 0.1360 - val_mae: 0.1360 - val_mse: 0.0454\n",
      "Epoch 100/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0717 - mae: 0.0717 - mse: 0.0154 - val_loss: 0.1511 - val_mae: 0.1511 - val_mse: 0.0521\n",
      "Epoch 101/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0686 - mae: 0.0686 - mse: 0.0152 - val_loss: 0.1428 - val_mae: 0.1428 - val_mse: 0.0470\n",
      "Epoch 102/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0661 - mae: 0.0661 - mse: 0.0143 - val_loss: 0.1397 - val_mae: 0.1397 - val_mse: 0.0454\n",
      "Epoch 103/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0676 - mae: 0.0676 - mse: 0.0143 - val_loss: 0.1513 - val_mae: 0.1513 - val_mse: 0.0481\n",
      "Epoch 104/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0665 - mae: 0.0665 - mse: 0.0145 - val_loss: 0.1419 - val_mae: 0.1419 - val_mse: 0.0471\n",
      "Epoch 105/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0634 - mae: 0.0634 - mse: 0.0142 - val_loss: 0.1464 - val_mae: 0.1464 - val_mse: 0.0515\n",
      "Epoch 106/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0662 - mae: 0.0662 - mse: 0.0147 - val_loss: 0.1295 - val_mae: 0.1295 - val_mse: 0.0414\n",
      "Epoch 107/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0690 - mae: 0.0690 - mse: 0.0136 - val_loss: 0.1509 - val_mae: 0.1509 - val_mse: 0.0551\n",
      "Epoch 108/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0685 - mae: 0.0685 - mse: 0.0141 - val_loss: 0.1379 - val_mae: 0.1379 - val_mse: 0.0432\n",
      "Epoch 109/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0644 - mae: 0.0644 - mse: 0.0139 - val_loss: 0.1410 - val_mae: 0.1410 - val_mse: 0.0482\n",
      "Epoch 110/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0596 - mae: 0.0596 - mse: 0.0129 - val_loss: 0.1442 - val_mae: 0.1442 - val_mse: 0.0472\n",
      "Epoch 111/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0648 - mae: 0.0648 - mse: 0.0139 - val_loss: 0.1363 - val_mae: 0.1363 - val_mse: 0.0468\n",
      "Epoch 112/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0709 - mae: 0.0709 - mse: 0.0156 - val_loss: 0.1497 - val_mae: 0.1497 - val_mse: 0.0525\n",
      "Epoch 113/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0699 - mae: 0.0699 - mse: 0.0150 - val_loss: 0.1428 - val_mae: 0.1428 - val_mse: 0.0490\n",
      "Epoch 114/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0697 - mae: 0.0697 - mse: 0.0143 - val_loss: 0.1487 - val_mae: 0.1487 - val_mse: 0.0494\n",
      "Epoch 115/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0637 - mae: 0.0637 - mse: 0.0136 - val_loss: 0.1365 - val_mae: 0.1365 - val_mse: 0.0477\n",
      "Epoch 116/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0654 - mae: 0.0654 - mse: 0.0138 - val_loss: 0.1418 - val_mae: 0.1418 - val_mse: 0.0488\n",
      "Epoch 117/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0644 - mae: 0.0644 - mse: 0.0138 - val_loss: 0.1339 - val_mae: 0.1339 - val_mse: 0.0442\n",
      "Epoch 118/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0645 - mae: 0.0645 - mse: 0.0129 - val_loss: 0.1422 - val_mae: 0.1422 - val_mse: 0.0503\n",
      "Epoch 119/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0664 - mae: 0.0664 - mse: 0.0135 - val_loss: 0.1508 - val_mae: 0.1508 - val_mse: 0.0530\n",
      "Epoch 120/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0680 - mae: 0.0680 - mse: 0.0141 - val_loss: 0.1445 - val_mae: 0.1445 - val_mse: 0.0504\n",
      "Epoch 121/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0625 - mae: 0.0625 - mse: 0.0131 - val_loss: 0.1458 - val_mae: 0.1458 - val_mse: 0.0520\n",
      "Epoch 122/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0624 - mae: 0.0624 - mse: 0.0124 - val_loss: 0.1388 - val_mae: 0.1388 - val_mse: 0.0455\n",
      "Epoch 123/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0640 - mae: 0.0640 - mse: 0.0133 - val_loss: 0.1437 - val_mae: 0.1437 - val_mse: 0.0512\n",
      "Epoch 124/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0614 - mae: 0.0614 - mse: 0.0126 - val_loss: 0.1378 - val_mae: 0.1378 - val_mse: 0.0480\n",
      "Epoch 125/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0623 - mae: 0.0623 - mse: 0.0128 - val_loss: 0.1465 - val_mae: 0.1465 - val_mse: 0.0551\n",
      "Epoch 126/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0647 - mae: 0.0647 - mse: 0.0122 - val_loss: 0.1385 - val_mae: 0.1385 - val_mse: 0.0490\n",
      "Epoch 127/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0621 - mae: 0.0621 - mse: 0.0129 - val_loss: 0.1384 - val_mae: 0.1384 - val_mse: 0.0475\n",
      "Epoch 128/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0565 - mae: 0.0565 - mse: 0.0124 - val_loss: 0.1362 - val_mae: 0.1362 - val_mse: 0.0441\n",
      "Epoch 129/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0611 - mae: 0.0611 - mse: 0.0128 - val_loss: 0.1479 - val_mae: 0.1479 - val_mse: 0.0524\n",
      "Epoch 130/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0665 - mae: 0.0665 - mse: 0.0135 - val_loss: 0.1468 - val_mae: 0.1468 - val_mse: 0.0471\n",
      "Epoch 131/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0640 - mae: 0.0640 - mse: 0.0122 - val_loss: 0.1433 - val_mae: 0.1433 - val_mse: 0.0484\n",
      "Epoch 132/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0613 - mae: 0.0613 - mse: 0.0120 - val_loss: 0.1348 - val_mae: 0.1348 - val_mse: 0.0454\n",
      "Epoch 133/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0585 - mae: 0.0585 - mse: 0.0113 - val_loss: 0.1381 - val_mae: 0.1381 - val_mse: 0.0473\n",
      "Epoch 134/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0584 - mae: 0.0584 - mse: 0.0117 - val_loss: 0.1508 - val_mae: 0.1508 - val_mse: 0.0555\n",
      "Epoch 135/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0590 - mae: 0.0590 - mse: 0.0115 - val_loss: 0.1348 - val_mae: 0.1348 - val_mse: 0.0476\n",
      "Epoch 136/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0564 - mae: 0.0564 - mse: 0.0115 - val_loss: 0.1408 - val_mae: 0.1408 - val_mse: 0.0479\n",
      "Epoch 137/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0555 - mae: 0.0555 - mse: 0.0110 - val_loss: 0.1401 - val_mae: 0.1401 - val_mse: 0.0481\n",
      "Epoch 138/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0576 - mae: 0.0576 - mse: 0.0112 - val_loss: 0.1463 - val_mae: 0.1463 - val_mse: 0.0502\n",
      "Epoch 139/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0605 - mae: 0.0605 - mse: 0.0124 - val_loss: 0.1422 - val_mae: 0.1422 - val_mse: 0.0502\n",
      "Epoch 140/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0573 - mae: 0.0573 - mse: 0.0105 - val_loss: 0.1386 - val_mae: 0.1386 - val_mse: 0.0470\n",
      "Epoch 141/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0556 - mae: 0.0556 - mse: 0.0102 - val_loss: 0.1388 - val_mae: 0.1388 - val_mse: 0.0481\n",
      "Epoch 142/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0596 - mae: 0.0596 - mse: 0.0120 - val_loss: 0.1392 - val_mae: 0.1392 - val_mse: 0.0505\n",
      "Epoch 143/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0530 - mae: 0.0530 - mse: 0.0103 - val_loss: 0.1417 - val_mae: 0.1417 - val_mse: 0.0506\n",
      "Epoch 144/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0591 - mae: 0.0591 - mse: 0.0113 - val_loss: 0.1386 - val_mae: 0.1386 - val_mse: 0.0506\n",
      "Epoch 145/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0518 - mae: 0.0518 - mse: 0.0098 - val_loss: 0.1358 - val_mae: 0.1358 - val_mse: 0.0489\n",
      "Epoch 146/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0539 - mae: 0.0539 - mse: 0.0109 - val_loss: 0.1384 - val_mae: 0.1384 - val_mse: 0.0447\n",
      "Epoch 147/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0578 - mae: 0.0578 - mse: 0.0109 - val_loss: 0.1359 - val_mae: 0.1359 - val_mse: 0.0439\n",
      "Epoch 148/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0598 - mae: 0.0598 - mse: 0.0113 - val_loss: 0.1475 - val_mae: 0.1475 - val_mse: 0.0521\n",
      "Epoch 149/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0655 - mae: 0.0655 - mse: 0.0116 - val_loss: 0.1366 - val_mae: 0.1366 - val_mse: 0.0453\n",
      "Epoch 150/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0547 - mae: 0.0547 - mse: 0.0104 - val_loss: 0.1393 - val_mae: 0.1393 - val_mse: 0.0470\n",
      "Epoch 151/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0515 - mae: 0.0515 - mse: 0.0102 - val_loss: 0.1475 - val_mae: 0.1475 - val_mse: 0.0476\n",
      "Epoch 152/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0583 - mae: 0.0583 - mse: 0.0108 - val_loss: 0.1377 - val_mae: 0.1377 - val_mse: 0.0493\n",
      "Epoch 153/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0592 - mae: 0.0592 - mse: 0.0119 - val_loss: 0.1468 - val_mae: 0.1468 - val_mse: 0.0492\n",
      "Epoch 154/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0627 - mae: 0.0627 - mse: 0.0135 - val_loss: 0.1424 - val_mae: 0.1424 - val_mse: 0.0497\n",
      "Epoch 155/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0510 - mae: 0.0510 - mse: 0.0098 - val_loss: 0.1348 - val_mae: 0.1348 - val_mse: 0.0466\n",
      "Epoch 156/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0548 - mae: 0.0548 - mse: 0.0101 - val_loss: 0.1360 - val_mae: 0.1360 - val_mse: 0.0495\n",
      "Epoch 157/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0565 - mae: 0.0565 - mse: 0.0105 - val_loss: 0.1402 - val_mae: 0.1402 - val_mse: 0.0464\n",
      "Epoch 158/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0548 - mae: 0.0548 - mse: 0.0103 - val_loss: 0.1496 - val_mae: 0.1496 - val_mse: 0.0499\n",
      "Epoch 159/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0563 - mae: 0.0563 - mse: 0.0108 - val_loss: 0.1511 - val_mae: 0.1511 - val_mse: 0.0496\n",
      "Epoch 160/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0514 - mae: 0.0514 - mse: 0.0094 - val_loss: 0.1322 - val_mae: 0.1322 - val_mse: 0.0436\n",
      "Epoch 161/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0545 - mae: 0.0545 - mse: 0.0110 - val_loss: 0.1342 - val_mae: 0.1342 - val_mse: 0.0441\n",
      "Epoch 162/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0524 - mae: 0.0524 - mse: 0.0101 - val_loss: 0.1398 - val_mae: 0.1398 - val_mse: 0.0524\n",
      "Epoch 163/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0553 - mae: 0.0553 - mse: 0.0098 - val_loss: 0.1479 - val_mae: 0.1479 - val_mse: 0.0532\n",
      "Epoch 164/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0591 - mae: 0.0591 - mse: 0.0108 - val_loss: 0.1360 - val_mae: 0.1360 - val_mse: 0.0472\n",
      "Epoch 165/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0501 - mae: 0.0501 - mse: 0.0095 - val_loss: 0.1337 - val_mae: 0.1337 - val_mse: 0.0471\n",
      "Epoch 166/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0524 - mae: 0.0524 - mse: 0.0098 - val_loss: 0.1381 - val_mae: 0.1381 - val_mse: 0.0478\n",
      "Epoch 167/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0563 - mae: 0.0563 - mse: 0.0101 - val_loss: 0.1335 - val_mae: 0.1335 - val_mse: 0.0456\n",
      "Epoch 168/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0530 - mae: 0.0530 - mse: 0.0097 - val_loss: 0.1454 - val_mae: 0.1454 - val_mse: 0.0501\n",
      "Epoch 169/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0567 - mae: 0.0567 - mse: 0.0106 - val_loss: 0.1460 - val_mae: 0.1460 - val_mse: 0.0452\n",
      "Epoch 170/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0571 - mae: 0.0571 - mse: 0.0109 - val_loss: 0.1365 - val_mae: 0.1365 - val_mse: 0.0472\n",
      "Epoch 171/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0550 - mae: 0.0550 - mse: 0.0098 - val_loss: 0.1362 - val_mae: 0.1362 - val_mse: 0.0447\n",
      "Epoch 172/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0488 - mae: 0.0488 - mse: 0.0088 - val_loss: 0.1371 - val_mae: 0.1371 - val_mse: 0.0482\n",
      "Epoch 173/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0487 - mae: 0.0487 - mse: 0.0095 - val_loss: 0.1362 - val_mae: 0.1362 - val_mse: 0.0457\n",
      "Epoch 174/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0493 - mae: 0.0493 - mse: 0.0090 - val_loss: 0.1305 - val_mae: 0.1305 - val_mse: 0.0434\n",
      "Epoch 175/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0502 - mae: 0.0502 - mse: 0.0092 - val_loss: 0.1349 - val_mae: 0.1349 - val_mse: 0.0450\n",
      "Epoch 176/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0496 - mae: 0.0496 - mse: 0.0090 - val_loss: 0.1404 - val_mae: 0.1404 - val_mse: 0.0469\n",
      "Epoch 177/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0574 - mae: 0.0574 - mse: 0.0109 - val_loss: 0.1275 - val_mae: 0.1275 - val_mse: 0.0436\n",
      "Epoch 178/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0498 - mae: 0.0498 - mse: 0.0091 - val_loss: 0.1355 - val_mae: 0.1355 - val_mse: 0.0449\n",
      "Epoch 179/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0507 - mae: 0.0507 - mse: 0.0093 - val_loss: 0.1383 - val_mae: 0.1383 - val_mse: 0.0483\n",
      "Epoch 180/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0503 - mae: 0.0503 - mse: 0.0091 - val_loss: 0.1315 - val_mae: 0.1315 - val_mse: 0.0444\n",
      "Epoch 181/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0502 - mae: 0.0502 - mse: 0.0091 - val_loss: 0.1408 - val_mae: 0.1408 - val_mse: 0.0508\n",
      "Epoch 182/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0555 - mae: 0.0555 - mse: 0.0106 - val_loss: 0.1366 - val_mae: 0.1366 - val_mse: 0.0449\n",
      "Epoch 183/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0563 - mae: 0.0563 - mse: 0.0099 - val_loss: 0.1404 - val_mae: 0.1404 - val_mse: 0.0471\n",
      "Epoch 184/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0514 - mae: 0.0514 - mse: 0.0091 - val_loss: 0.1247 - val_mae: 0.1247 - val_mse: 0.0391\n",
      "Epoch 185/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0537 - mae: 0.0537 - mse: 0.0097 - val_loss: 0.1340 - val_mae: 0.1340 - val_mse: 0.0451\n",
      "Epoch 186/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0517 - mae: 0.0517 - mse: 0.0095 - val_loss: 0.1370 - val_mae: 0.1370 - val_mse: 0.0442\n",
      "Epoch 187/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0578 - mae: 0.0578 - mse: 0.0112 - val_loss: 0.1371 - val_mae: 0.1371 - val_mse: 0.0476\n",
      "Epoch 188/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0506 - mae: 0.0506 - mse: 0.0090 - val_loss: 0.1312 - val_mae: 0.1312 - val_mse: 0.0457\n",
      "Epoch 189/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0495 - mae: 0.0495 - mse: 0.0084 - val_loss: 0.1376 - val_mae: 0.1376 - val_mse: 0.0443\n",
      "Epoch 190/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0498 - mae: 0.0498 - mse: 0.0089 - val_loss: 0.1342 - val_mae: 0.1342 - val_mse: 0.0433\n",
      "Epoch 191/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0502 - mae: 0.0502 - mse: 0.0093 - val_loss: 0.1254 - val_mae: 0.1254 - val_mse: 0.0408\n",
      "Epoch 192/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0491 - mae: 0.0491 - mse: 0.0089 - val_loss: 0.1310 - val_mae: 0.1310 - val_mse: 0.0447\n",
      "Epoch 193/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0458 - mae: 0.0458 - mse: 0.0080 - val_loss: 0.1332 - val_mae: 0.1332 - val_mse: 0.0446\n",
      "Epoch 194/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0468 - mae: 0.0468 - mse: 0.0083 - val_loss: 0.1343 - val_mae: 0.1343 - val_mse: 0.0428\n",
      "Epoch 195/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0496 - mae: 0.0496 - mse: 0.0083 - val_loss: 0.1412 - val_mae: 0.1412 - val_mse: 0.0488\n",
      "Epoch 196/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0565 - mae: 0.0565 - mse: 0.0104 - val_loss: 0.1377 - val_mae: 0.1377 - val_mse: 0.0451\n",
      "Epoch 197/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0504 - mae: 0.0504 - mse: 0.0089 - val_loss: 0.1339 - val_mae: 0.1339 - val_mse: 0.0457\n",
      "Epoch 198/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0471 - mae: 0.0471 - mse: 0.0085 - val_loss: 0.1438 - val_mae: 0.1438 - val_mse: 0.0462\n",
      "Epoch 199/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0569 - mae: 0.0569 - mse: 0.0105 - val_loss: 0.1319 - val_mae: 0.1319 - val_mse: 0.0409\n",
      "Epoch 200/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0525 - mae: 0.0525 - mse: 0.0093 - val_loss: 0.1291 - val_mae: 0.1291 - val_mse: 0.0402\n",
      "Epoch 201/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0510 - mae: 0.0510 - mse: 0.0088 - val_loss: 0.1407 - val_mae: 0.1407 - val_mse: 0.0426\n",
      "Epoch 202/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0488 - mae: 0.0488 - mse: 0.0091 - val_loss: 0.1362 - val_mae: 0.1362 - val_mse: 0.0467\n",
      "Epoch 203/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0450 - mae: 0.0450 - mse: 0.0080 - val_loss: 0.1399 - val_mae: 0.1399 - val_mse: 0.0481\n",
      "Epoch 204/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0512 - mae: 0.0512 - mse: 0.0093 - val_loss: 0.1344 - val_mae: 0.1344 - val_mse: 0.0409\n",
      "Epoch 205/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0471 - mae: 0.0471 - mse: 0.0084 - val_loss: 0.1532 - val_mae: 0.1532 - val_mse: 0.0506\n",
      "Epoch 206/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0558 - mae: 0.0558 - mse: 0.0099 - val_loss: 0.1344 - val_mae: 0.1344 - val_mse: 0.0448\n",
      "Epoch 207/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0498 - mae: 0.0498 - mse: 0.0094 - val_loss: 0.1277 - val_mae: 0.1277 - val_mse: 0.0445\n",
      "Epoch 208/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0502 - mae: 0.0502 - mse: 0.0083 - val_loss: 0.1385 - val_mae: 0.1385 - val_mse: 0.0437\n",
      "Epoch 209/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0471 - mae: 0.0471 - mse: 0.0079 - val_loss: 0.1263 - val_mae: 0.1263 - val_mse: 0.0396\n",
      "Epoch 210/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0470 - mae: 0.0470 - mse: 0.0084 - val_loss: 0.1362 - val_mae: 0.1362 - val_mse: 0.0443\n",
      "Epoch 211/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0499 - mae: 0.0499 - mse: 0.0085 - val_loss: 0.1349 - val_mae: 0.1349 - val_mse: 0.0424\n",
      "Epoch 212/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0470 - mae: 0.0470 - mse: 0.0080 - val_loss: 0.1283 - val_mae: 0.1283 - val_mse: 0.0408\n",
      "Epoch 213/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0529 - mae: 0.0529 - mse: 0.0097 - val_loss: 0.1260 - val_mae: 0.1260 - val_mse: 0.0404\n",
      "Epoch 214/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0525 - mae: 0.0525 - mse: 0.0086 - val_loss: 0.1423 - val_mae: 0.1423 - val_mse: 0.0438\n",
      "Epoch 215/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0511 - mae: 0.0511 - mse: 0.0086 - val_loss: 0.1373 - val_mae: 0.1373 - val_mse: 0.0442\n",
      "Epoch 216/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0477 - mae: 0.0477 - mse: 0.0084 - val_loss: 0.1398 - val_mae: 0.1398 - val_mse: 0.0460\n",
      "Epoch 217/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0462 - mae: 0.0462 - mse: 0.0078 - val_loss: 0.1275 - val_mae: 0.1275 - val_mse: 0.0401\n",
      "Epoch 218/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0477 - mae: 0.0477 - mse: 0.0080 - val_loss: 0.1319 - val_mae: 0.1319 - val_mse: 0.0397\n",
      "Epoch 219/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0462 - mae: 0.0462 - mse: 0.0085 - val_loss: 0.1327 - val_mae: 0.1327 - val_mse: 0.0413\n",
      "Epoch 220/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0422 - mae: 0.0422 - mse: 0.0075 - val_loss: 0.1294 - val_mae: 0.1294 - val_mse: 0.0409\n",
      "Epoch 221/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0443 - mae: 0.0443 - mse: 0.0079 - val_loss: 0.1319 - val_mae: 0.1319 - val_mse: 0.0436\n",
      "Epoch 222/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0488 - mae: 0.0488 - mse: 0.0081 - val_loss: 0.1468 - val_mae: 0.1468 - val_mse: 0.0518\n",
      "Epoch 223/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0650 - mae: 0.0650 - mse: 0.0114 - val_loss: 0.1462 - val_mae: 0.1462 - val_mse: 0.0497\n",
      "Epoch 224/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0645 - mae: 0.0645 - mse: 0.0151 - val_loss: 0.1345 - val_mae: 0.1345 - val_mse: 0.0468\n",
      "Epoch 225/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0507 - mae: 0.0507 - mse: 0.0089 - val_loss: 0.1353 - val_mae: 0.1353 - val_mse: 0.0444\n",
      "Epoch 226/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0444 - mae: 0.0444 - mse: 0.0077 - val_loss: 0.1312 - val_mae: 0.1312 - val_mse: 0.0440\n",
      "Epoch 227/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0454 - mae: 0.0454 - mse: 0.0080 - val_loss: 0.1361 - val_mae: 0.1361 - val_mse: 0.0454\n",
      "Epoch 228/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0533 - mae: 0.0533 - mse: 0.0089 - val_loss: 0.1419 - val_mae: 0.1419 - val_mse: 0.0425\n",
      "Epoch 229/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0512 - mae: 0.0512 - mse: 0.0084 - val_loss: 0.1367 - val_mae: 0.1367 - val_mse: 0.0437\n",
      "Epoch 230/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0452 - mae: 0.0452 - mse: 0.0078 - val_loss: 0.1358 - val_mae: 0.1358 - val_mse: 0.0427\n",
      "Epoch 231/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0505 - mae: 0.0505 - mse: 0.0086 - val_loss: 0.1350 - val_mae: 0.1350 - val_mse: 0.0471\n",
      "Epoch 232/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0486 - mae: 0.0486 - mse: 0.0088 - val_loss: 0.1322 - val_mae: 0.1322 - val_mse: 0.0416\n",
      "Epoch 233/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0478 - mae: 0.0478 - mse: 0.0077 - val_loss: 0.1387 - val_mae: 0.1387 - val_mse: 0.0427\n",
      "Epoch 234/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0494 - mae: 0.0494 - mse: 0.0079 - val_loss: 0.1379 - val_mae: 0.1379 - val_mse: 0.0412\n",
      "Epoch 235/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0537 - mae: 0.0537 - mse: 0.0088 - val_loss: 0.1299 - val_mae: 0.1299 - val_mse: 0.0421\n",
      "Epoch 236/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0503 - mae: 0.0503 - mse: 0.0082 - val_loss: 0.1377 - val_mae: 0.1377 - val_mse: 0.0422\n",
      "Epoch 237/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0507 - mae: 0.0507 - mse: 0.0082 - val_loss: 0.1301 - val_mae: 0.1301 - val_mse: 0.0411\n",
      "Epoch 238/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0473 - mae: 0.0473 - mse: 0.0081 - val_loss: 0.1284 - val_mae: 0.1284 - val_mse: 0.0404\n",
      "Epoch 239/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0457 - mae: 0.0457 - mse: 0.0079 - val_loss: 0.1325 - val_mae: 0.1325 - val_mse: 0.0415\n",
      "Epoch 240/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0445 - mae: 0.0445 - mse: 0.0078 - val_loss: 0.1292 - val_mae: 0.1292 - val_mse: 0.0394\n",
      "Epoch 241/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0483 - mae: 0.0483 - mse: 0.0086 - val_loss: 0.1388 - val_mae: 0.1388 - val_mse: 0.0430\n",
      "Epoch 242/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0464 - mae: 0.0464 - mse: 0.0079 - val_loss: 0.1268 - val_mae: 0.1268 - val_mse: 0.0402\n",
      "Epoch 243/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0415 - mae: 0.0415 - mse: 0.0068 - val_loss: 0.1283 - val_mae: 0.1283 - val_mse: 0.0397\n",
      "Epoch 244/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0446 - mae: 0.0446 - mse: 0.0073 - val_loss: 0.1338 - val_mae: 0.1338 - val_mse: 0.0402\n",
      "Epoch 245/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0541 - mae: 0.0541 - mse: 0.0095 - val_loss: 0.1468 - val_mae: 0.1468 - val_mse: 0.0481\n",
      "Epoch 246/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0476 - mae: 0.0476 - mse: 0.0078 - val_loss: 0.1327 - val_mae: 0.1327 - val_mse: 0.0425\n",
      "Epoch 247/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0450 - mae: 0.0450 - mse: 0.0081 - val_loss: 0.1322 - val_mae: 0.1322 - val_mse: 0.0444\n",
      "Epoch 248/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0431 - mae: 0.0431 - mse: 0.0074 - val_loss: 0.1300 - val_mae: 0.1300 - val_mse: 0.0402\n",
      "Epoch 249/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0475 - mae: 0.0475 - mse: 0.0084 - val_loss: 0.1421 - val_mae: 0.1421 - val_mse: 0.0475\n",
      "Epoch 250/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0473 - mae: 0.0473 - mse: 0.0076 - val_loss: 0.1323 - val_mae: 0.1323 - val_mse: 0.0410\n",
      "Epoch 251/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0512 - mae: 0.0512 - mse: 0.0081 - val_loss: 0.1351 - val_mae: 0.1351 - val_mse: 0.0432\n",
      "Epoch 252/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0450 - mae: 0.0450 - mse: 0.0074 - val_loss: 0.1343 - val_mae: 0.1343 - val_mse: 0.0437\n",
      "Epoch 253/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0479 - mae: 0.0479 - mse: 0.0076 - val_loss: 0.1248 - val_mae: 0.1248 - val_mse: 0.0418\n",
      "Epoch 254/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0460 - mae: 0.0460 - mse: 0.0076 - val_loss: 0.1246 - val_mae: 0.1246 - val_mse: 0.0390\n",
      "Epoch 255/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0440 - mae: 0.0440 - mse: 0.0071 - val_loss: 0.1284 - val_mae: 0.1284 - val_mse: 0.0389\n",
      "Epoch 256/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0442 - mae: 0.0442 - mse: 0.0074 - val_loss: 0.1266 - val_mae: 0.1266 - val_mse: 0.0396\n",
      "Epoch 257/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0408 - mae: 0.0408 - mse: 0.0070 - val_loss: 0.1280 - val_mae: 0.1280 - val_mse: 0.0373\n",
      "Epoch 258/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0402 - mae: 0.0402 - mse: 0.0067 - val_loss: 0.1304 - val_mae: 0.1304 - val_mse: 0.0444\n",
      "Epoch 259/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0414 - mae: 0.0414 - mse: 0.0069 - val_loss: 0.1298 - val_mae: 0.1298 - val_mse: 0.0400\n",
      "Epoch 260/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0469 - mae: 0.0469 - mse: 0.0069 - val_loss: 0.1294 - val_mae: 0.1294 - val_mse: 0.0404\n",
      "Epoch 261/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0468 - mae: 0.0468 - mse: 0.0075 - val_loss: 0.1383 - val_mae: 0.1383 - val_mse: 0.0447\n",
      "Epoch 262/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0465 - mae: 0.0465 - mse: 0.0078 - val_loss: 0.1324 - val_mae: 0.1324 - val_mse: 0.0439\n",
      "Epoch 263/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0468 - mae: 0.0468 - mse: 0.0078 - val_loss: 0.1284 - val_mae: 0.1284 - val_mse: 0.0426\n",
      "Epoch 264/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0486 - mae: 0.0486 - mse: 0.0079 - val_loss: 0.1326 - val_mae: 0.1326 - val_mse: 0.0418\n",
      "Epoch 265/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0433 - mae: 0.0433 - mse: 0.0071 - val_loss: 0.1320 - val_mae: 0.1320 - val_mse: 0.0427\n",
      "Epoch 266/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0429 - mae: 0.0429 - mse: 0.0074 - val_loss: 0.1357 - val_mae: 0.1357 - val_mse: 0.0432\n",
      "Epoch 267/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0497 - mae: 0.0497 - mse: 0.0082 - val_loss: 0.1332 - val_mae: 0.1332 - val_mse: 0.0398\n",
      "Epoch 268/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0434 - mae: 0.0434 - mse: 0.0068 - val_loss: 0.1342 - val_mae: 0.1342 - val_mse: 0.0399\n",
      "Epoch 269/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0426 - mae: 0.0426 - mse: 0.0068 - val_loss: 0.1350 - val_mae: 0.1350 - val_mse: 0.0436\n",
      "Epoch 270/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0462 - mae: 0.0462 - mse: 0.0079 - val_loss: 0.1304 - val_mae: 0.1304 - val_mse: 0.0407\n",
      "Epoch 271/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0381 - mae: 0.0381 - mse: 0.0062 - val_loss: 0.1316 - val_mae: 0.1316 - val_mse: 0.0440\n",
      "Epoch 272/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0412 - mae: 0.0412 - mse: 0.0066 - val_loss: 0.1277 - val_mae: 0.1277 - val_mse: 0.0400\n",
      "Epoch 273/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0419 - mae: 0.0419 - mse: 0.0071 - val_loss: 0.1393 - val_mae: 0.1393 - val_mse: 0.0454\n",
      "Epoch 274/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0453 - mae: 0.0453 - mse: 0.0072 - val_loss: 0.1324 - val_mae: 0.1324 - val_mse: 0.0399\n",
      "Epoch 275/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0419 - mae: 0.0419 - mse: 0.0068 - val_loss: 0.1295 - val_mae: 0.1295 - val_mse: 0.0412\n",
      "Epoch 276/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0399 - mae: 0.0399 - mse: 0.0064 - val_loss: 0.1336 - val_mae: 0.1336 - val_mse: 0.0439\n",
      "Epoch 277/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0439 - mae: 0.0439 - mse: 0.0070 - val_loss: 0.1285 - val_mae: 0.1285 - val_mse: 0.0382\n",
      "Epoch 278/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0448 - mae: 0.0448 - mse: 0.0076 - val_loss: 0.1293 - val_mae: 0.1293 - val_mse: 0.0436\n",
      "Epoch 279/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0411 - mae: 0.0411 - mse: 0.0061 - val_loss: 0.1303 - val_mae: 0.1303 - val_mse: 0.0402\n",
      "Epoch 280/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0427 - mae: 0.0427 - mse: 0.0067 - val_loss: 0.1376 - val_mae: 0.1376 - val_mse: 0.0443\n",
      "Epoch 281/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0491 - mae: 0.0491 - mse: 0.0080 - val_loss: 0.1236 - val_mae: 0.1236 - val_mse: 0.0370\n",
      "Epoch 282/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0431 - mae: 0.0431 - mse: 0.0065 - val_loss: 0.1332 - val_mae: 0.1332 - val_mse: 0.0449\n",
      "Epoch 283/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0418 - mae: 0.0418 - mse: 0.0065 - val_loss: 0.1273 - val_mae: 0.1273 - val_mse: 0.0388\n",
      "Epoch 284/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0392 - mae: 0.0392 - mse: 0.0062 - val_loss: 0.1301 - val_mae: 0.1301 - val_mse: 0.0389\n",
      "Epoch 285/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0420 - mae: 0.0420 - mse: 0.0068 - val_loss: 0.1354 - val_mae: 0.1354 - val_mse: 0.0413\n",
      "Epoch 286/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0479 - mae: 0.0479 - mse: 0.0074 - val_loss: 0.1326 - val_mae: 0.1326 - val_mse: 0.0436\n",
      "Epoch 287/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0437 - mae: 0.0437 - mse: 0.0070 - val_loss: 0.1295 - val_mae: 0.1295 - val_mse: 0.0412\n",
      "Epoch 288/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0437 - mae: 0.0437 - mse: 0.0077 - val_loss: 0.1301 - val_mae: 0.1301 - val_mse: 0.0418\n",
      "Epoch 289/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0389 - mae: 0.0389 - mse: 0.0062 - val_loss: 0.1313 - val_mae: 0.1313 - val_mse: 0.0403\n",
      "Epoch 290/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0522 - mae: 0.0522 - mse: 0.0085 - val_loss: 0.1286 - val_mae: 0.1286 - val_mse: 0.0412\n",
      "Epoch 291/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0445 - mae: 0.0445 - mse: 0.0068 - val_loss: 0.1291 - val_mae: 0.1291 - val_mse: 0.0410\n",
      "Epoch 292/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0427 - mae: 0.0427 - mse: 0.0061 - val_loss: 0.1280 - val_mae: 0.1280 - val_mse: 0.0373\n",
      "Epoch 293/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0499 - mae: 0.0499 - mse: 0.0080 - val_loss: 0.1251 - val_mae: 0.1251 - val_mse: 0.0373\n",
      "Epoch 294/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0429 - mae: 0.0429 - mse: 0.0067 - val_loss: 0.1268 - val_mae: 0.1268 - val_mse: 0.0405\n",
      "Epoch 295/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0377 - mae: 0.0377 - mse: 0.0065 - val_loss: 0.1295 - val_mae: 0.1295 - val_mse: 0.0410\n",
      "Epoch 296/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0407 - mae: 0.0407 - mse: 0.0066 - val_loss: 0.1342 - val_mae: 0.1342 - val_mse: 0.0427\n",
      "Epoch 297/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0424 - mae: 0.0424 - mse: 0.0068 - val_loss: 0.1292 - val_mae: 0.1292 - val_mse: 0.0399\n",
      "Epoch 298/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0428 - mae: 0.0428 - mse: 0.0070 - val_loss: 0.1288 - val_mae: 0.1288 - val_mse: 0.0377\n",
      "Epoch 299/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0395 - mae: 0.0395 - mse: 0.0066 - val_loss: 0.1339 - val_mae: 0.1339 - val_mse: 0.0418\n",
      "Epoch 300/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0441 - mae: 0.0441 - mse: 0.0067 - val_loss: 0.1347 - val_mae: 0.1347 - val_mse: 0.0411\n",
      "Epoch 301/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0398 - mae: 0.0398 - mse: 0.0058 - val_loss: 0.1330 - val_mae: 0.1330 - val_mse: 0.0395\n",
      "Epoch 302/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0459 - mae: 0.0459 - mse: 0.0075 - val_loss: 0.1373 - val_mae: 0.1373 - val_mse: 0.0426\n",
      "Epoch 303/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0414 - mae: 0.0414 - mse: 0.0067 - val_loss: 0.1256 - val_mae: 0.1256 - val_mse: 0.0393\n",
      "Epoch 304/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0423 - mae: 0.0423 - mse: 0.0068 - val_loss: 0.1386 - val_mae: 0.1386 - val_mse: 0.0422\n",
      "Epoch 305/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0463 - mae: 0.0463 - mse: 0.0073 - val_loss: 0.1401 - val_mae: 0.1401 - val_mse: 0.0470\n",
      "Epoch 306/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0460 - mae: 0.0460 - mse: 0.0080 - val_loss: 0.1314 - val_mae: 0.1314 - val_mse: 0.0429\n",
      "Epoch 307/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0450 - mae: 0.0450 - mse: 0.0070 - val_loss: 0.1315 - val_mae: 0.1315 - val_mse: 0.0398\n",
      "Epoch 308/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0426 - mae: 0.0426 - mse: 0.0066 - val_loss: 0.1302 - val_mae: 0.1302 - val_mse: 0.0408\n",
      "Epoch 309/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0397 - mae: 0.0397 - mse: 0.0060 - val_loss: 0.1385 - val_mae: 0.1385 - val_mse: 0.0423\n",
      "Epoch 310/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0400 - mae: 0.0400 - mse: 0.0060 - val_loss: 0.1322 - val_mae: 0.1322 - val_mse: 0.0429\n",
      "Epoch 311/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0390 - mae: 0.0390 - mse: 0.0062 - val_loss: 0.1285 - val_mae: 0.1285 - val_mse: 0.0408\n",
      "Epoch 312/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0448 - mae: 0.0448 - mse: 0.0073 - val_loss: 0.1376 - val_mae: 0.1376 - val_mse: 0.0428\n",
      "Epoch 313/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0406 - mae: 0.0406 - mse: 0.0060 - val_loss: 0.1354 - val_mae: 0.1354 - val_mse: 0.0465\n",
      "Epoch 314/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0408 - mae: 0.0408 - mse: 0.0067 - val_loss: 0.1264 - val_mae: 0.1264 - val_mse: 0.0379\n",
      "Epoch 315/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0409 - mae: 0.0409 - mse: 0.0064 - val_loss: 0.1369 - val_mae: 0.1369 - val_mse: 0.0430\n",
      "Epoch 316/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0425 - mae: 0.0425 - mse: 0.0066 - val_loss: 0.1387 - val_mae: 0.1387 - val_mse: 0.0423\n",
      "Epoch 317/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0413 - mae: 0.0413 - mse: 0.0063 - val_loss: 0.1332 - val_mae: 0.1332 - val_mse: 0.0430\n",
      "Epoch 318/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0419 - mae: 0.0419 - mse: 0.0072 - val_loss: 0.1312 - val_mae: 0.1312 - val_mse: 0.0409\n",
      "Epoch 319/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0430 - mae: 0.0430 - mse: 0.0066 - val_loss: 0.1396 - val_mae: 0.1396 - val_mse: 0.0423\n",
      "Epoch 320/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0402 - mae: 0.0402 - mse: 0.0061 - val_loss: 0.1463 - val_mae: 0.1463 - val_mse: 0.0480\n",
      "Epoch 321/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0467 - mae: 0.0467 - mse: 0.0078 - val_loss: 0.1334 - val_mae: 0.1334 - val_mse: 0.0428\n",
      "Epoch 322/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0391 - mae: 0.0391 - mse: 0.0060 - val_loss: 0.1295 - val_mae: 0.1295 - val_mse: 0.0411\n",
      "Epoch 323/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0378 - mae: 0.0378 - mse: 0.0066 - val_loss: 0.1340 - val_mae: 0.1340 - val_mse: 0.0411\n",
      "Epoch 324/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0413 - mae: 0.0413 - mse: 0.0063 - val_loss: 0.1346 - val_mae: 0.1346 - val_mse: 0.0421\n",
      "Epoch 325/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0374 - mae: 0.0374 - mse: 0.0066 - val_loss: 0.1308 - val_mae: 0.1308 - val_mse: 0.0392\n",
      "Epoch 326/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0436 - mae: 0.0436 - mse: 0.0068 - val_loss: 0.1273 - val_mae: 0.1273 - val_mse: 0.0390\n",
      "Epoch 327/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0438 - mae: 0.0438 - mse: 0.0066 - val_loss: 0.1310 - val_mae: 0.1310 - val_mse: 0.0394\n",
      "Epoch 328/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0409 - mae: 0.0409 - mse: 0.0064 - val_loss: 0.1323 - val_mae: 0.1323 - val_mse: 0.0416\n",
      "Epoch 329/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0404 - mae: 0.0404 - mse: 0.0059 - val_loss: 0.1327 - val_mae: 0.1327 - val_mse: 0.0433\n",
      "Epoch 330/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0427 - mae: 0.0427 - mse: 0.0061 - val_loss: 0.1253 - val_mae: 0.1253 - val_mse: 0.0389\n",
      "Epoch 331/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0391 - mae: 0.0391 - mse: 0.0060 - val_loss: 0.1274 - val_mae: 0.1274 - val_mse: 0.0380\n",
      "Epoch 332/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0445 - mae: 0.0445 - mse: 0.0072 - val_loss: 0.1284 - val_mae: 0.1284 - val_mse: 0.0385\n",
      "Epoch 333/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0401 - mae: 0.0401 - mse: 0.0057 - val_loss: 0.1346 - val_mae: 0.1346 - val_mse: 0.0442\n",
      "Epoch 334/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0393 - mae: 0.0393 - mse: 0.0059 - val_loss: 0.1264 - val_mae: 0.1264 - val_mse: 0.0375\n",
      "Epoch 335/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0387 - mae: 0.0387 - mse: 0.0059 - val_loss: 0.1309 - val_mae: 0.1309 - val_mse: 0.0411\n",
      "Epoch 336/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0370 - mae: 0.0370 - mse: 0.0059 - val_loss: 0.1308 - val_mae: 0.1308 - val_mse: 0.0401\n",
      "Epoch 337/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0401 - mae: 0.0401 - mse: 0.0059 - val_loss: 0.1352 - val_mae: 0.1352 - val_mse: 0.0404\n",
      "Epoch 338/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0407 - mae: 0.0407 - mse: 0.0067 - val_loss: 0.1272 - val_mae: 0.1272 - val_mse: 0.0399\n",
      "Epoch 339/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0364 - mae: 0.0364 - mse: 0.0055 - val_loss: 0.1323 - val_mae: 0.1323 - val_mse: 0.0400\n",
      "Epoch 340/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0419 - mae: 0.0419 - mse: 0.0062 - val_loss: 0.1318 - val_mae: 0.1318 - val_mse: 0.0416\n",
      "Epoch 341/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0361 - mae: 0.0361 - mse: 0.0053 - val_loss: 0.1343 - val_mae: 0.1343 - val_mse: 0.0437\n",
      "Epoch 342/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0360 - mae: 0.0360 - mse: 0.0055 - val_loss: 0.1291 - val_mae: 0.1291 - val_mse: 0.0380\n",
      "Epoch 343/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0402 - mae: 0.0402 - mse: 0.0062 - val_loss: 0.1304 - val_mae: 0.1304 - val_mse: 0.0402\n",
      "Epoch 344/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0356 - mae: 0.0356 - mse: 0.0060 - val_loss: 0.1334 - val_mae: 0.1334 - val_mse: 0.0408\n",
      "Epoch 345/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0355 - mae: 0.0355 - mse: 0.0054 - val_loss: 0.1271 - val_mae: 0.1271 - val_mse: 0.0393\n",
      "Epoch 346/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0368 - mae: 0.0368 - mse: 0.0059 - val_loss: 0.1289 - val_mae: 0.1289 - val_mse: 0.0427\n",
      "Epoch 347/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0381 - mae: 0.0381 - mse: 0.0057 - val_loss: 0.1404 - val_mae: 0.1404 - val_mse: 0.0439\n",
      "Epoch 348/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0372 - mae: 0.0372 - mse: 0.0057 - val_loss: 0.1342 - val_mae: 0.1342 - val_mse: 0.0406\n",
      "Epoch 349/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0380 - mae: 0.0380 - mse: 0.0062 - val_loss: 0.1327 - val_mae: 0.1327 - val_mse: 0.0408\n",
      "Epoch 350/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0429 - mae: 0.0429 - mse: 0.0065 - val_loss: 0.1335 - val_mae: 0.1335 - val_mse: 0.0406\n",
      "Epoch 351/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0403 - mae: 0.0403 - mse: 0.0070 - val_loss: 0.1236 - val_mae: 0.1236 - val_mse: 0.0379\n",
      "Epoch 352/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0425 - mae: 0.0425 - mse: 0.0070 - val_loss: 0.1344 - val_mae: 0.1344 - val_mse: 0.0449\n",
      "Epoch 353/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0395 - mae: 0.0395 - mse: 0.0059 - val_loss: 0.1280 - val_mae: 0.1280 - val_mse: 0.0379\n",
      "Epoch 354/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0430 - mae: 0.0430 - mse: 0.0067 - val_loss: 0.1257 - val_mae: 0.1257 - val_mse: 0.0392\n",
      "Epoch 355/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0377 - mae: 0.0377 - mse: 0.0057 - val_loss: 0.1317 - val_mae: 0.1317 - val_mse: 0.0431\n",
      "Epoch 356/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0382 - mae: 0.0382 - mse: 0.0057 - val_loss: 0.1262 - val_mae: 0.1262 - val_mse: 0.0367\n",
      "Epoch 357/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0366 - mae: 0.0366 - mse: 0.0058 - val_loss: 0.1318 - val_mae: 0.1318 - val_mse: 0.0389\n",
      "Epoch 358/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0435 - mae: 0.0435 - mse: 0.0065 - val_loss: 0.1325 - val_mae: 0.1325 - val_mse: 0.0420\n",
      "Epoch 359/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0391 - mae: 0.0391 - mse: 0.0055 - val_loss: 0.1270 - val_mae: 0.1270 - val_mse: 0.0369\n",
      "Epoch 360/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0382 - mae: 0.0382 - mse: 0.0057 - val_loss: 0.1271 - val_mae: 0.1271 - val_mse: 0.0386\n",
      "Epoch 361/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0392 - mae: 0.0392 - mse: 0.0064 - val_loss: 0.1283 - val_mae: 0.1283 - val_mse: 0.0391\n",
      "Epoch 362/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0383 - mae: 0.0383 - mse: 0.0055 - val_loss: 0.1257 - val_mae: 0.1257 - val_mse: 0.0395\n",
      "Epoch 363/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0361 - mae: 0.0361 - mse: 0.0055 - val_loss: 0.1270 - val_mae: 0.1270 - val_mse: 0.0377\n",
      "Epoch 364/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0376 - mae: 0.0376 - mse: 0.0065 - val_loss: 0.1288 - val_mae: 0.1288 - val_mse: 0.0397\n",
      "Epoch 365/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0404 - mae: 0.0404 - mse: 0.0057 - val_loss: 0.1264 - val_mae: 0.1264 - val_mse: 0.0373\n",
      "Epoch 366/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0372 - mae: 0.0372 - mse: 0.0060 - val_loss: 0.1282 - val_mae: 0.1282 - val_mse: 0.0389\n",
      "Epoch 367/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0352 - mae: 0.0352 - mse: 0.0052 - val_loss: 0.1304 - val_mae: 0.1304 - val_mse: 0.0388\n",
      "Epoch 368/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0382 - mae: 0.0382 - mse: 0.0056 - val_loss: 0.1227 - val_mae: 0.1227 - val_mse: 0.0367\n",
      "Epoch 369/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0379 - mae: 0.0379 - mse: 0.0059 - val_loss: 0.1300 - val_mae: 0.1300 - val_mse: 0.0382\n",
      "Epoch 370/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0384 - mae: 0.0384 - mse: 0.0060 - val_loss: 0.1304 - val_mae: 0.1304 - val_mse: 0.0397\n",
      "Epoch 371/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0382 - mae: 0.0382 - mse: 0.0057 - val_loss: 0.1297 - val_mae: 0.1297 - val_mse: 0.0374\n",
      "Epoch 372/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0461 - mae: 0.0461 - mse: 0.0064 - val_loss: 0.1249 - val_mae: 0.1249 - val_mse: 0.0378\n",
      "Epoch 373/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0381 - mae: 0.0381 - mse: 0.0055 - val_loss: 0.1303 - val_mae: 0.1303 - val_mse: 0.0396\n",
      "Epoch 374/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0376 - mae: 0.0376 - mse: 0.0056 - val_loss: 0.1255 - val_mae: 0.1255 - val_mse: 0.0378\n",
      "Epoch 375/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0350 - mae: 0.0350 - mse: 0.0051 - val_loss: 0.1265 - val_mae: 0.1265 - val_mse: 0.0405\n",
      "Epoch 376/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0438 - mae: 0.0438 - mse: 0.0073 - val_loss: 0.1302 - val_mae: 0.1302 - val_mse: 0.0410\n",
      "Epoch 377/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0415 - mae: 0.0415 - mse: 0.0062 - val_loss: 0.1293 - val_mae: 0.1293 - val_mse: 0.0385\n",
      "Epoch 378/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0410 - mae: 0.0410 - mse: 0.0063 - val_loss: 0.1295 - val_mae: 0.1295 - val_mse: 0.0408\n",
      "Epoch 379/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0366 - mae: 0.0366 - mse: 0.0059 - val_loss: 0.1356 - val_mae: 0.1356 - val_mse: 0.0433\n",
      "Epoch 380/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0363 - mae: 0.0363 - mse: 0.0054 - val_loss: 0.1285 - val_mae: 0.1285 - val_mse: 0.0372\n",
      "Epoch 381/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0373 - mae: 0.0373 - mse: 0.0054 - val_loss: 0.1301 - val_mae: 0.1301 - val_mse: 0.0399\n",
      "Epoch 382/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0348 - mae: 0.0348 - mse: 0.0053 - val_loss: 0.1272 - val_mae: 0.1272 - val_mse: 0.0393\n",
      "Epoch 383/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0324 - mae: 0.0324 - mse: 0.0048 - val_loss: 0.1290 - val_mae: 0.1290 - val_mse: 0.0393\n",
      "Epoch 384/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0381 - mae: 0.0381 - mse: 0.0054 - val_loss: 0.1268 - val_mae: 0.1268 - val_mse: 0.0375\n",
      "Epoch 385/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0356 - mae: 0.0356 - mse: 0.0049 - val_loss: 0.1297 - val_mae: 0.1297 - val_mse: 0.0370\n",
      "Epoch 386/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0378 - mae: 0.0378 - mse: 0.0055 - val_loss: 0.1339 - val_mae: 0.1339 - val_mse: 0.0432\n",
      "Epoch 387/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0397 - mae: 0.0397 - mse: 0.0054 - val_loss: 0.1262 - val_mae: 0.1262 - val_mse: 0.0388\n",
      "Epoch 388/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0346 - mae: 0.0346 - mse: 0.0052 - val_loss: 0.1255 - val_mae: 0.1255 - val_mse: 0.0376\n",
      "Epoch 389/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0344 - mae: 0.0344 - mse: 0.0048 - val_loss: 0.1297 - val_mae: 0.1297 - val_mse: 0.0368\n",
      "Epoch 390/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0359 - mae: 0.0359 - mse: 0.0057 - val_loss: 0.1331 - val_mae: 0.1331 - val_mse: 0.0378\n",
      "Epoch 391/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0444 - mae: 0.0444 - mse: 0.0059 - val_loss: 0.1412 - val_mae: 0.1412 - val_mse: 0.0434\n",
      "Epoch 392/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0390 - mae: 0.0390 - mse: 0.0059 - val_loss: 0.1304 - val_mae: 0.1304 - val_mse: 0.0401\n",
      "Epoch 393/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0351 - mae: 0.0351 - mse: 0.0052 - val_loss: 0.1242 - val_mae: 0.1242 - val_mse: 0.0368\n",
      "Epoch 394/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0342 - mae: 0.0342 - mse: 0.0054 - val_loss: 0.1283 - val_mae: 0.1283 - val_mse: 0.0390\n",
      "Epoch 395/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0315 - mae: 0.0315 - mse: 0.0045 - val_loss: 0.1258 - val_mae: 0.1258 - val_mse: 0.0362\n",
      "Epoch 396/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0349 - mae: 0.0349 - mse: 0.0054 - val_loss: 0.1291 - val_mae: 0.1291 - val_mse: 0.0403\n",
      "Epoch 397/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0378 - mae: 0.0378 - mse: 0.0052 - val_loss: 0.1284 - val_mae: 0.1284 - val_mse: 0.0383\n",
      "Epoch 398/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0411 - mae: 0.0411 - mse: 0.0067 - val_loss: 0.1289 - val_mae: 0.1289 - val_mse: 0.0397\n",
      "Epoch 399/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0365 - mae: 0.0365 - mse: 0.0049 - val_loss: 0.1299 - val_mae: 0.1299 - val_mse: 0.0397\n",
      "Epoch 400/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0350 - mae: 0.0350 - mse: 0.0053 - val_loss: 0.1300 - val_mae: 0.1300 - val_mse: 0.0395\n",
      "Epoch 401/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0373 - mae: 0.0373 - mse: 0.0058 - val_loss: 0.1336 - val_mae: 0.1336 - val_mse: 0.0397\n",
      "Epoch 402/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0423 - mae: 0.0423 - mse: 0.0059 - val_loss: 0.1247 - val_mae: 0.1247 - val_mse: 0.0353\n",
      "Epoch 403/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0385 - mae: 0.0385 - mse: 0.0054 - val_loss: 0.1305 - val_mae: 0.1305 - val_mse: 0.0393\n",
      "Epoch 404/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0325 - mae: 0.0325 - mse: 0.0051 - val_loss: 0.1276 - val_mae: 0.1276 - val_mse: 0.0382\n",
      "Epoch 405/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0401 - mae: 0.0401 - mse: 0.0056 - val_loss: 0.1267 - val_mae: 0.1267 - val_mse: 0.0404\n",
      "Epoch 406/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0407 - mae: 0.0407 - mse: 0.0054 - val_loss: 0.1298 - val_mae: 0.1298 - val_mse: 0.0379\n",
      "Epoch 407/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0414 - mae: 0.0414 - mse: 0.0062 - val_loss: 0.1215 - val_mae: 0.1215 - val_mse: 0.0373\n",
      "Epoch 408/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0352 - mae: 0.0352 - mse: 0.0050 - val_loss: 0.1336 - val_mae: 0.1336 - val_mse: 0.0426\n",
      "Epoch 409/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0360 - mae: 0.0360 - mse: 0.0053 - val_loss: 0.1247 - val_mae: 0.1247 - val_mse: 0.0378\n",
      "Epoch 410/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0307 - mae: 0.0307 - mse: 0.0046 - val_loss: 0.1274 - val_mae: 0.1274 - val_mse: 0.0383\n",
      "Epoch 411/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0347 - mae: 0.0347 - mse: 0.0052 - val_loss: 0.1225 - val_mae: 0.1225 - val_mse: 0.0375\n",
      "Epoch 412/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0330 - mae: 0.0330 - mse: 0.0052 - val_loss: 0.1328 - val_mae: 0.1328 - val_mse: 0.0440\n",
      "Epoch 413/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0348 - mae: 0.0348 - mse: 0.0050 - val_loss: 0.1277 - val_mae: 0.1277 - val_mse: 0.0385\n",
      "Epoch 414/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0352 - mae: 0.0352 - mse: 0.0052 - val_loss: 0.1305 - val_mae: 0.1305 - val_mse: 0.0372\n",
      "Epoch 415/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0384 - mae: 0.0384 - mse: 0.0053 - val_loss: 0.1276 - val_mae: 0.1276 - val_mse: 0.0407\n",
      "Epoch 416/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0350 - mae: 0.0350 - mse: 0.0050 - val_loss: 0.1236 - val_mae: 0.1236 - val_mse: 0.0380\n",
      "Epoch 417/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0359 - mae: 0.0359 - mse: 0.0049 - val_loss: 0.1329 - val_mae: 0.1329 - val_mse: 0.0421\n",
      "Epoch 418/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0376 - mae: 0.0376 - mse: 0.0050 - val_loss: 0.1309 - val_mae: 0.1309 - val_mse: 0.0384\n",
      "Epoch 419/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0348 - mae: 0.0348 - mse: 0.0053 - val_loss: 0.1277 - val_mae: 0.1277 - val_mse: 0.0351\n",
      "Epoch 420/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0340 - mae: 0.0340 - mse: 0.0055 - val_loss: 0.1252 - val_mae: 0.1252 - val_mse: 0.0375\n",
      "Epoch 421/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0362 - mae: 0.0362 - mse: 0.0049 - val_loss: 0.1335 - val_mae: 0.1335 - val_mse: 0.0404\n",
      "Epoch 422/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0382 - mae: 0.0382 - mse: 0.0052 - val_loss: 0.1361 - val_mae: 0.1361 - val_mse: 0.0393\n",
      "Epoch 423/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0405 - mae: 0.0405 - mse: 0.0054 - val_loss: 0.1288 - val_mae: 0.1288 - val_mse: 0.0394\n",
      "Epoch 424/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0382 - mae: 0.0382 - mse: 0.0053 - val_loss: 0.1300 - val_mae: 0.1300 - val_mse: 0.0376\n",
      "Epoch 425/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0333 - mae: 0.0333 - mse: 0.0046 - val_loss: 0.1308 - val_mae: 0.1308 - val_mse: 0.0406\n",
      "Epoch 426/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0358 - mae: 0.0358 - mse: 0.0044 - val_loss: 0.1297 - val_mae: 0.1297 - val_mse: 0.0419\n",
      "Epoch 427/500\n",
      "25/25 - 0s - 3ms/step - loss: 0.0406 - mae: 0.0406 - mse: 0.0057 - val_loss: 0.1296 - val_mae: 0.1296 - val_mse: 0.0381\n",
      "Epoch 428/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0392 - mae: 0.0392 - mse: 0.0047 - val_loss: 0.1312 - val_mae: 0.1312 - val_mse: 0.0382\n",
      "Epoch 429/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0359 - mae: 0.0359 - mse: 0.0049 - val_loss: 0.1283 - val_mae: 0.1283 - val_mse: 0.0374\n",
      "Epoch 430/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0384 - mae: 0.0384 - mse: 0.0055 - val_loss: 0.1259 - val_mae: 0.1259 - val_mse: 0.0359\n",
      "Epoch 431/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0366 - mae: 0.0366 - mse: 0.0056 - val_loss: 0.1241 - val_mae: 0.1241 - val_mse: 0.0384\n",
      "Epoch 432/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0343 - mae: 0.0343 - mse: 0.0049 - val_loss: 0.1304 - val_mae: 0.1304 - val_mse: 0.0408\n",
      "Epoch 433/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0324 - mae: 0.0324 - mse: 0.0043 - val_loss: 0.1319 - val_mae: 0.1319 - val_mse: 0.0383\n",
      "Epoch 434/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0342 - mae: 0.0342 - mse: 0.0047 - val_loss: 0.1292 - val_mae: 0.1292 - val_mse: 0.0385\n",
      "Epoch 435/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0357 - mae: 0.0357 - mse: 0.0048 - val_loss: 0.1258 - val_mae: 0.1258 - val_mse: 0.0361\n",
      "Epoch 436/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0345 - mae: 0.0345 - mse: 0.0048 - val_loss: 0.1281 - val_mae: 0.1281 - val_mse: 0.0379\n",
      "Epoch 437/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0371 - mae: 0.0371 - mse: 0.0051 - val_loss: 0.1273 - val_mae: 0.1273 - val_mse: 0.0400\n",
      "Epoch 438/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0395 - mae: 0.0395 - mse: 0.0059 - val_loss: 0.1223 - val_mae: 0.1223 - val_mse: 0.0354\n",
      "Epoch 439/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0365 - mae: 0.0365 - mse: 0.0049 - val_loss: 0.1313 - val_mae: 0.1313 - val_mse: 0.0385\n",
      "Epoch 440/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0353 - mae: 0.0353 - mse: 0.0049 - val_loss: 0.1249 - val_mae: 0.1249 - val_mse: 0.0412\n",
      "Epoch 441/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0327 - mae: 0.0327 - mse: 0.0047 - val_loss: 0.1261 - val_mae: 0.1261 - val_mse: 0.0408\n",
      "Epoch 442/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0341 - mae: 0.0341 - mse: 0.0046 - val_loss: 0.1310 - val_mae: 0.1310 - val_mse: 0.0394\n",
      "Epoch 443/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0349 - mae: 0.0349 - mse: 0.0046 - val_loss: 0.1295 - val_mae: 0.1295 - val_mse: 0.0406\n",
      "Epoch 444/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0368 - mae: 0.0368 - mse: 0.0048 - val_loss: 0.1249 - val_mae: 0.1249 - val_mse: 0.0373\n",
      "Epoch 445/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0425 - mae: 0.0425 - mse: 0.0056 - val_loss: 0.1278 - val_mae: 0.1278 - val_mse: 0.0363\n",
      "Epoch 446/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0376 - mae: 0.0376 - mse: 0.0050 - val_loss: 0.1294 - val_mae: 0.1294 - val_mse: 0.0398\n",
      "Epoch 447/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0354 - mae: 0.0354 - mse: 0.0044 - val_loss: 0.1360 - val_mae: 0.1360 - val_mse: 0.0448\n",
      "Epoch 448/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0334 - mae: 0.0334 - mse: 0.0044 - val_loss: 0.1224 - val_mae: 0.1224 - val_mse: 0.0358\n",
      "Epoch 449/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0338 - mae: 0.0338 - mse: 0.0052 - val_loss: 0.1224 - val_mae: 0.1224 - val_mse: 0.0347\n",
      "Epoch 450/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0351 - mae: 0.0351 - mse: 0.0054 - val_loss: 0.1299 - val_mae: 0.1299 - val_mse: 0.0378\n",
      "Epoch 451/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0315 - mae: 0.0315 - mse: 0.0043 - val_loss: 0.1250 - val_mae: 0.1250 - val_mse: 0.0373\n",
      "Epoch 452/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0318 - mae: 0.0318 - mse: 0.0046 - val_loss: 0.1280 - val_mae: 0.1280 - val_mse: 0.0381\n",
      "Epoch 453/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0322 - mae: 0.0322 - mse: 0.0046 - val_loss: 0.1270 - val_mae: 0.1270 - val_mse: 0.0369\n",
      "Epoch 454/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0371 - mae: 0.0371 - mse: 0.0047 - val_loss: 0.1221 - val_mae: 0.1221 - val_mse: 0.0353\n",
      "Epoch 455/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0349 - mae: 0.0349 - mse: 0.0052 - val_loss: 0.1207 - val_mae: 0.1207 - val_mse: 0.0351\n",
      "Epoch 456/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0341 - mae: 0.0341 - mse: 0.0045 - val_loss: 0.1273 - val_mae: 0.1273 - val_mse: 0.0409\n",
      "Epoch 457/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0343 - mae: 0.0343 - mse: 0.0047 - val_loss: 0.1272 - val_mae: 0.1272 - val_mse: 0.0366\n",
      "Epoch 458/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0343 - mae: 0.0343 - mse: 0.0046 - val_loss: 0.1291 - val_mae: 0.1291 - val_mse: 0.0371\n",
      "Epoch 459/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0316 - mae: 0.0316 - mse: 0.0046 - val_loss: 0.1243 - val_mae: 0.1243 - val_mse: 0.0359\n",
      "Epoch 460/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0326 - mae: 0.0326 - mse: 0.0044 - val_loss: 0.1208 - val_mae: 0.1208 - val_mse: 0.0378\n",
      "Epoch 461/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0309 - mae: 0.0309 - mse: 0.0041 - val_loss: 0.1171 - val_mae: 0.1171 - val_mse: 0.0345\n",
      "Epoch 462/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0312 - mae: 0.0312 - mse: 0.0041 - val_loss: 0.1261 - val_mae: 0.1261 - val_mse: 0.0379\n",
      "Epoch 463/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0331 - mae: 0.0331 - mse: 0.0045 - val_loss: 0.1287 - val_mae: 0.1287 - val_mse: 0.0387\n",
      "Epoch 464/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0342 - mae: 0.0342 - mse: 0.0046 - val_loss: 0.1235 - val_mae: 0.1235 - val_mse: 0.0382\n",
      "Epoch 465/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0352 - mae: 0.0352 - mse: 0.0045 - val_loss: 0.1202 - val_mae: 0.1202 - val_mse: 0.0373\n",
      "Epoch 466/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0368 - mae: 0.0368 - mse: 0.0049 - val_loss: 0.1321 - val_mae: 0.1321 - val_mse: 0.0394\n",
      "Epoch 467/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0396 - mae: 0.0396 - mse: 0.0051 - val_loss: 0.1257 - val_mae: 0.1257 - val_mse: 0.0368\n",
      "Epoch 468/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0391 - mae: 0.0391 - mse: 0.0051 - val_loss: 0.1273 - val_mae: 0.1273 - val_mse: 0.0393\n",
      "Epoch 469/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0339 - mae: 0.0339 - mse: 0.0050 - val_loss: 0.1301 - val_mae: 0.1301 - val_mse: 0.0400\n",
      "Epoch 470/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0363 - mae: 0.0363 - mse: 0.0049 - val_loss: 0.1221 - val_mae: 0.1221 - val_mse: 0.0384\n",
      "Epoch 471/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0316 - mae: 0.0316 - mse: 0.0041 - val_loss: 0.1259 - val_mae: 0.1259 - val_mse: 0.0380\n",
      "Epoch 472/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0368 - mae: 0.0368 - mse: 0.0044 - val_loss: 0.1296 - val_mae: 0.1296 - val_mse: 0.0412\n",
      "Epoch 473/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0355 - mae: 0.0355 - mse: 0.0042 - val_loss: 0.1231 - val_mae: 0.1231 - val_mse: 0.0355\n",
      "Epoch 474/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0343 - mae: 0.0343 - mse: 0.0044 - val_loss: 0.1274 - val_mae: 0.1274 - val_mse: 0.0393\n",
      "Epoch 475/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0326 - mae: 0.0326 - mse: 0.0047 - val_loss: 0.1288 - val_mae: 0.1288 - val_mse: 0.0391\n",
      "Epoch 476/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0363 - mae: 0.0363 - mse: 0.0047 - val_loss: 0.1215 - val_mae: 0.1215 - val_mse: 0.0349\n",
      "Epoch 477/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0332 - mae: 0.0332 - mse: 0.0046 - val_loss: 0.1274 - val_mae: 0.1274 - val_mse: 0.0370\n",
      "Epoch 478/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0356 - mae: 0.0356 - mse: 0.0051 - val_loss: 0.1282 - val_mae: 0.1282 - val_mse: 0.0373\n",
      "Epoch 479/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0333 - mae: 0.0333 - mse: 0.0043 - val_loss: 0.1316 - val_mae: 0.1316 - val_mse: 0.0425\n",
      "Epoch 480/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0331 - mae: 0.0331 - mse: 0.0049 - val_loss: 0.1250 - val_mae: 0.1250 - val_mse: 0.0386\n",
      "Epoch 481/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0310 - mae: 0.0310 - mse: 0.0045 - val_loss: 0.1247 - val_mae: 0.1247 - val_mse: 0.0373\n",
      "Epoch 482/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0319 - mae: 0.0319 - mse: 0.0041 - val_loss: 0.1293 - val_mae: 0.1293 - val_mse: 0.0381\n",
      "Epoch 483/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0336 - mae: 0.0336 - mse: 0.0047 - val_loss: 0.1305 - val_mae: 0.1305 - val_mse: 0.0429\n",
      "Epoch 484/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0308 - mae: 0.0308 - mse: 0.0039 - val_loss: 0.1237 - val_mae: 0.1237 - val_mse: 0.0357\n",
      "Epoch 485/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0300 - mae: 0.0300 - mse: 0.0038 - val_loss: 0.1257 - val_mae: 0.1257 - val_mse: 0.0403\n",
      "Epoch 486/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0314 - mae: 0.0314 - mse: 0.0039 - val_loss: 0.1261 - val_mae: 0.1261 - val_mse: 0.0371\n",
      "Epoch 487/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0339 - mae: 0.0339 - mse: 0.0047 - val_loss: 0.1290 - val_mae: 0.1290 - val_mse: 0.0394\n",
      "Epoch 488/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0318 - mae: 0.0318 - mse: 0.0044 - val_loss: 0.1256 - val_mae: 0.1256 - val_mse: 0.0366\n",
      "Epoch 489/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0309 - mae: 0.0309 - mse: 0.0040 - val_loss: 0.1238 - val_mae: 0.1238 - val_mse: 0.0370\n",
      "Epoch 490/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0315 - mae: 0.0315 - mse: 0.0038 - val_loss: 0.1235 - val_mae: 0.1235 - val_mse: 0.0363\n",
      "Epoch 491/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0307 - mae: 0.0307 - mse: 0.0039 - val_loss: 0.1231 - val_mae: 0.1231 - val_mse: 0.0373\n",
      "Epoch 492/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0328 - mae: 0.0328 - mse: 0.0047 - val_loss: 0.1284 - val_mae: 0.1284 - val_mse: 0.0375\n",
      "Epoch 493/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0319 - mae: 0.0319 - mse: 0.0042 - val_loss: 0.1306 - val_mae: 0.1306 - val_mse: 0.0380\n",
      "Epoch 494/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0333 - mae: 0.0333 - mse: 0.0046 - val_loss: 0.1277 - val_mae: 0.1277 - val_mse: 0.0369\n",
      "Epoch 495/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0343 - mae: 0.0343 - mse: 0.0050 - val_loss: 0.1275 - val_mae: 0.1275 - val_mse: 0.0415\n",
      "Epoch 496/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0349 - mae: 0.0349 - mse: 0.0047 - val_loss: 0.1291 - val_mae: 0.1291 - val_mse: 0.0381\n",
      "Epoch 497/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0367 - mae: 0.0367 - mse: 0.0049 - val_loss: 0.1273 - val_mae: 0.1273 - val_mse: 0.0388\n",
      "Epoch 498/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0337 - mae: 0.0337 - mse: 0.0046 - val_loss: 0.1253 - val_mae: 0.1253 - val_mse: 0.0398\n",
      "Epoch 499/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0362 - mae: 0.0362 - mse: 0.0050 - val_loss: 0.1310 - val_mae: 0.1310 - val_mse: 0.0391\n",
      "Epoch 500/500\n",
      "25/25 - 0s - 4ms/step - loss: 0.0325 - mae: 0.0325 - mse: 0.0040 - val_loss: 0.1239 - val_mae: 0.1239 - val_mse: 0.0382\n",
      "Model training time: 0:00:50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,485</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,040</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,050</span> \n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)                      \u001b[38;5;34m2,485\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m140\u001b[0m)                     \u001b[38;5;34m5,040\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                      \u001b[38;5;34m7,050\u001b[0m \n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m51\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,880</span> (171.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,880\u001b[0m (171.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,626</span> (57.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,626\u001b[0m (57.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,254</span> (114.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m29,254\u001b[0m (114.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: [0.10525383800268173, 0.10525383800268173, 0.01687234453856945]\n",
      "mae = 0.10525383800268173\n",
      "mse = 0.01687234453856945\n"
     ]
    }
   ],
   "source": [
    "epochs_number = 500\n",
    "\n",
    "model = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Dense(size, activation='relu'), \n",
    "    tf.keras.layers.Dense(140, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)                      \n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics=['mae', 'mse']\n",
    "model.compile(optimizer=optimizer, loss='mae', metrics=metrics)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# history  =  model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=2)\n",
    "start = time.time()\n",
    "history  =  model.fit(X_train, y_train, epochs=epochs_number, batch_size=32, validation_split=0.1, verbose=2)\n",
    "end = time.time()\n",
    "transcription_time = calculate_time(round((end - start),2))\n",
    "print(f\"Model training time: \"+transcription_time)\n",
    "model.summary()\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Metrics:\",results)\n",
    "for index, metric in enumerate(metrics):\n",
    "    print(f\"{metric} = {results[index+1]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc31826-eab8-43c1-a40b-2eb3583d188d",
   "metadata": {},
   "source": [
    "Model training time without gpu, epoch = 1000 : 0:01:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab0ae957-c0b9-44b6-96c3-371aedd188ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, verbose=0)\n",
    "predictions = output_scaler.inverse_transform(predictions)\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_test = output_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4bc09ed-6f62-4d32-946f-5cabb1786468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " przewidywana --> [833.32477]     [1041.9] <-- rzeczyswista     blad: [208.57523193]   Data58 5_4 850-45m\n",
      " przewidywana --> [399.3131]     [378.] <-- rzeczyswista     blad: [21.31311035]   Data115 1 CAC1900\n",
      " przewidywana --> [749.86035]     [770.1] <-- rzeczyswista     blad: [20.23964844]   Data58 5_3 800-1h\n",
      " przewidywana --> [1422.8309]     [1343.] <-- rzeczyswista     blad: [79.83093262]   Data150 4 10stC\n",
      " przewidywana --> [573.7731]     [659.] <-- rzeczyswista     blad: [85.22692871]   Data7 3 RK-600\n",
      " przewidywana --> [760.4452]     [817.2] <-- rzeczyswista     blad: [56.75480957]   Data58 5_3 800-1h15m\n",
      " przewidywana --> [1279.4666]     [1387.] <-- rzeczyswista     blad: [107.53344727]   Data65 2_2 R2-500\n",
      " przewidywana --> [2147.8801]     [2064.] <-- rzeczyswista     blad: [83.88012695]   Data59 2 CMS500\n",
      " przewidywana --> [502.0672]     [448.] <-- rzeczyswista     blad: [54.06719971]   Data43 6 F1-8-11\n",
      " przewidywana --> [1772.851]     [1784.] <-- rzeczyswista     blad: [11.14904785]   Data27 1 KUA21701-2\n",
      " przewidywana --> [1286.5903]     [1305.] <-- rzeczyswista     blad: [18.40966797]   Data27 1 KUA21701-200\n",
      " przewidywana --> [46.254513]     [80.8] <-- rzeczyswista     blad: [34.54548721]   Data48 1_1 2\n",
      " przewidywana --> [884.54675]     [864.] <-- rzeczyswista     blad: [20.54675293]   Data61 1 CB\n",
      " przewidywana --> [918.4827]     [976.2] <-- rzeczyswista     blad: [57.71727295]   Data43 8 F2-66\n",
      " przewidywana --> [678.30743]     [620.] <-- rzeczyswista     blad: [58.30743408]   Data79 2 0.25-C\n",
      " przewidywana --> [1014.5821]     [1165.8] <-- rzeczyswista     blad: [151.21790771]   Data91 3_1 AC-Gly\n",
      " przewidywana --> [1498.1124]     [1426.] <-- rzeczyswista     blad: [72.11242676]   Data156 1 K1\n",
      " przewidywana --> [535.0798]     [400.] <-- rzeczyswista     blad: [135.07977295]   Data119 6 Xp0.50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take the length of shape with unknown rank.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     23\u001b[0m max_error_sample_name \u001b[38;5;241m=\u001b[39m y_test_nested\u001b[38;5;241m.\u001b[39miloc[max_error_index,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     24\u001b[0m text_to_display \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZwykly: max error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  dla \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_error_data_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_error_graph_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_error_sample_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor error thteshold[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m((\u001b[38;5;28mlen\u001b[39m(list_below)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(predictions))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(list_below)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m izotermy na \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m,results)\n\u001b[1;32m     31\u001b[0m metrics_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/adorbents-isotherms-FmcCsTt1-py3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/adorbents-isotherms-FmcCsTt1-py3.12/lib/python3.12/site-packages/optree/ops.py:752\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    750\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    751\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take the length of shape with unknown rank."
     ]
    }
   ],
   "source": [
    "error_threshold = 30\n",
    "max_error_threshold = 30\n",
    "\n",
    "list_below =[]\n",
    "list_above=[]\n",
    "errors = []\n",
    "for i in range(len(predictions)):\n",
    "    data_name = y_test_nested.iloc[i,0]\n",
    "    graph_number = y_test_nested.iloc[i,1]\n",
    "    sample_name = y_test_nested.iloc[i,2]\n",
    "    error = abs(predictions[i] - y_test[i])\n",
    "    \n",
    "    errors.append(error)\n",
    "    if(error_threshold<=error):\n",
    "        list_above.append(i)\n",
    "    else: list_below.append(i)\n",
    "    print(f\" przewidywana --> {predictions[i]}     {y_test[i]} <-- rzeczyswista     blad: {error}   {data_name} {graph_number} {sample_name}\")\n",
    "\n",
    "    \n",
    "max_error_index = errors.index(max(errors))\n",
    "max_error_data_name = y_test_nested.iloc[max_error_index,0]\n",
    "max_error_graph_number = y_test_nested.iloc[max_error_index,1]\n",
    "max_error_sample_name = y_test_nested.iloc[max_error_index,2]\n",
    "text_to_display = f\"Zwykly: max error: {max(errors)}  dla {max_error_data_name} {max_error_graph_number} {max_error_sample_name}  \"  + \"\\n\" + f\"for error thteshold[{error_threshold}] - {round((len(list_below)/len(predictions))*100,2)}%     {len(list_below)} izotermy na {len(predictions)}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Metrics:\",results)\n",
    "metrics_text = \"\"\n",
    "for index, metric in enumerate(metrics):\n",
    "    metrics_text = metrics_text + f\"{metric} = {results[index+1]:.2f}\" + \"\\n\"\n",
    "    print(f\"{metric} = {results[index+1]}\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15,5))\n",
    "\n",
    "min_loss_idx = history.history['loss'].index(min(history.history['loss']))\n",
    "min_loss = min(history.history['loss'])# Get the lowest  value\n",
    "ax[0].plot(history.history['loss'], color='teal', label='mae')\n",
    "# ax[0].plot(history.history['val_total_loss'], color='orange', label='val loss')\n",
    "ax[0].title.set_text('Loss [mae]')\n",
    "ax[0].legend()\n",
    "ax[0].annotate(f'Min: {min_loss:.2f} \\nfor {min_loss_idx} epoch', \n",
    "               xy=(min_loss_idx, min_loss), \n",
    "               xytext=(min_loss_idx - 1 , min_loss + 1),  # Adjust text position\n",
    "               arrowprops=dict(facecolor='red', arrowstyle=\"->\"),\n",
    "               color='red')\n",
    "ax[0].plot(min_loss_idx, min_loss, 'ro',markersize=3)# Plot a dot at the minimum point\n",
    "ax[0].text(0.5, 0.8, text_to_display, horizontalalignment='center', verticalalignment='center',fontsize=10, transform=ax[0].transAxes)\n",
    "\n",
    "min_val_loss_idx = history.history['val_loss'].index(min(history.history['val_loss']))# Find the index of the minimum \n",
    "min_val_loss = min(history.history['val_loss'])# Get the lowest  value\n",
    "ax[1].plot(history.history['val_loss'], color='teal', label='mae')\n",
    "# ax[1].plot(hist.history['val_class_loss'], color='orange', label='val class loss')\n",
    "ax[1].title.set_text('Validation Loss [mae]')\n",
    "ax[1].legend()\n",
    "# Annotate the lowest point on the validation loss curve\n",
    "ax[1].annotate(f'Min: {min_val_loss:.2f} \\nfor {min_val_loss_idx} epoch', \n",
    "               xy=(min_val_loss_idx, min_val_loss), \n",
    "               xytext=(min_val_loss_idx - 1, min_val_loss + 1),  # Adjust text position\n",
    "               arrowprops=dict(facecolor='red', arrowstyle=\"->\"),\n",
    "               color='red')\n",
    "ax[1].plot(min_val_loss_idx, min_val_loss, 'ro', markersize=3)# Plot a dot at the minimum point\n",
    "ax[1].text(0.5, 0.8, metrics_text, horizontalalignment='center', verticalalignment='center',fontsize=10, transform=ax[1].transAxes)\n",
    "# ax[2].plot(history.history['val_mse'], color='teal', label='regress loss')\n",
    "# # ax[2].plot(hist.history['val_regress_loss'], color='orange', label='val regress loss')\n",
    "# ax[2].title.set_text('Validation mse')\n",
    "# ax[2].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('scaler_v1.jpg', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30680080-e5b9-4cb2-ae27-badd5f61ba30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL:\n",
      " przewidywana --> [921.3797]     1041.9 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [439.41388]     378.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [745.89233]     770.1 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [1389.339]     1343.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [599.79803]     659.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [776.3266]     817.2 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [1353.6625]     1387.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [1957.6586]     2064.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [473.38864]     448.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [1800.5452]     1784.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [1335.5308]     1305.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [32.117325]     80.8 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [769.17]     864.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [988.49396]     976.2 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [492.823]     620.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [1103.536]     1165.8 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [1571.639]     1426.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      " przewidywana --> [501.6467]     400.0 <-- rzeczyswista     blad: [101.646698]   Data119 6 Xp0.50\n",
      "max error: [145.63903809]  dla Data156 1 K1  \n",
      "for error thteshold[30] - 22.22%     4 izotermy na 18\n"
     ]
    }
   ],
   "source": [
    "error_threshold = 30\n",
    "max_error_threshold = 30\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "list_below =[]\n",
    "list_above=[]\n",
    "errors = []\n",
    "for i in range(len(predictions)):\n",
    "    data_name = y_test_nested.iloc[i,0]\n",
    "    graph_number = y_test_nested.iloc[i,1]\n",
    "    sample_name = y_test_nested.iloc[i,2]\n",
    "    error = abs(predictions[i] - y_test[i])\n",
    "    \n",
    "    errors.append(error)\n",
    "    if(error_threshold<=error):\n",
    "        list_above.append(i)\n",
    "    else: list_below.append(i)\n",
    "\n",
    "print(\"\\nALL:\")\n",
    "for i in range(len(predictions)):\n",
    "    print(f\" przewidywana --> {predictions[i]}     {y_test[i]} <-- rzeczyswista     blad: {error}   {data_name} {graph_number} {sample_name}\")\n",
    "max_error_index = errors.index(max(errors))\n",
    "max_error_data_name = y_test_nested.iloc[max_error_index,0]\n",
    "max_error_graph_number = y_test_nested.iloc[max_error_index,1]\n",
    "max_error_sample_name = y_test_nested.iloc[max_error_index,2]\n",
    "print(f\"max error: {max(errors)}  dla {max_error_data_name} {max_error_graph_number} {max_error_sample_name}  \" )\n",
    "print(f\"for error thteshold[{error_threshold}] - {round((len(list_below)/len(predictions))*100,2)}%     {len(list_below)} izotermy na {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46990393-9831-4eb4-b1d8-42f369bdb13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec0df54b-f327-423a-93c9-9dd9d337b790",
   "metadata": {},
   "source": [
    "# scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "459cea83-0e19-4044-a567-5c5b4f87dd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL:\n",
      " przewidywana --> [955.6867]     [1041.9] <-- rzeczyswista     blad: [86.21329346]   Data58 5_4 850-45m\n",
      " przewidywana --> [481.1255]     [378.] <-- rzeczyswista     blad: [103.12548828]   Data115 1 CAC1900\n",
      " przewidywana --> [775.2813]     [770.1] <-- rzeczyswista     blad: [5.18131104]   Data58 5_3 800-1h\n",
      " przewidywana --> [1433.7211]     [1343.] <-- rzeczyswista     blad: [90.72106934]   Data150 4 10stC\n",
      " przewidywana --> [599.39343]     [659.] <-- rzeczyswista     blad: [59.60656738]   Data7 3 RK-600\n",
      " przewidywana --> [771.859]     [817.2] <-- rzeczyswista     blad: [45.34099121]   Data58 5_3 800-1h15m\n",
      " przewidywana --> [1326.1232]     [1387.] <-- rzeczyswista     blad: [60.87683105]   Data65 2_2 R2-500\n",
      " przewidywana --> [2161.0364]     [2064.] <-- rzeczyswista     blad: [97.03637695]   Data59 2 CMS500\n",
      " przewidywana --> [434.49414]     [448.] <-- rzeczyswista     blad: [13.50585938]   Data43 6 F1-8-11\n",
      " przewidywana --> [1782.0216]     [1784.] <-- rzeczyswista     blad: [1.97839355]   Data27 1 KUA21701-2\n",
      " przewidywana --> [1304.4686]     [1305.] <-- rzeczyswista     blad: [0.53137207]   Data27 1 KUA21701-200\n",
      " przewidywana --> [62.11883]     [80.8] <-- rzeczyswista     blad: [18.68116837]   Data48 1_1 2\n",
      " przewidywana --> [763.6345]     [864.] <-- rzeczyswista     blad: [100.36547852]   Data61 1 CB\n",
      " przewidywana --> [901.16364]     [976.2] <-- rzeczyswista     blad: [75.03636475]   Data43 8 F2-66\n",
      " przewidywana --> [638.1774]     [620.] <-- rzeczyswista     blad: [18.1774292]   Data79 2 0.25-C\n",
      " przewidywana --> [1090.6102]     [1165.8] <-- rzeczyswista     blad: [75.18977051]   Data91 3_1 AC-Gly\n",
      " przewidywana --> [1530.7283]     [1426.] <-- rzeczyswista     blad: [104.72827148]   Data156 1 K1\n",
      " przewidywana --> [493.00287]     [400.] <-- rzeczyswista     blad: [93.00286865]   Data119 6 Xp0.50\n",
      "max error: [104.72827148]  dla Data156 1 K1  \n",
      "for error thteshold[30] - 33.33%     6 izotermy na 18\n"
     ]
    }
   ],
   "source": [
    "error_threshold = 30\n",
    "max_error_threshold = 30\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "predictions = output_scaler.inverse_transform(predictions)\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_test = output_scaler.inverse_transform(y_test)\n",
    "list_below =[]\n",
    "list_above=[]\n",
    "errors = []\n",
    "for i in range(len(predictions)):\n",
    "    errors.append(abs(predictions[i] - y_test[i]))\n",
    "    # print(f\"{i} {predictions[i]}  ------   {y_valid[i]}           blad: {abs(predictions[i] - y_valid[i])}\")\n",
    "    # if(abs(predictions[i] - y_test[i]) > max_error_threshold):\n",
    "    #     print(f\" przewidywana --> {predictions[i]}     {y_test[i]} <-- rzeczyswista     blad: {abs(predictions[i] - y_test[i])}  {y_test_nested[i][1]}\")\n",
    "        \n",
    "    if(error_threshold<=abs(predictions[i] - y_test[i])):\n",
    "        list_above.append(i)\n",
    "    else: list_below.append(i)\n",
    "\n",
    "print(\"\\nALL:\")\n",
    "for i in range(len(predictions)):\n",
    "    print(f\" przewidywana --> {predictions[i]}     {y_test[i]} <-- rzeczyswista     blad: {abs(predictions[i] - y_test[i])}   {y_test_nested.iloc[i,0]} {y_test_nested.iloc[i,1]} {y_test_nested.iloc[i,2]}\")\n",
    "\n",
    "print(f\"max error: {max(errors)}  dla {y_test_nested.iloc[errors.index(max(errors)),0]} {y_test_nested.iloc[errors.index(max(errors)),1]} {y_test_nested.iloc[errors.index(max(errors)),2]}  \" )\n",
    "print(f\"for error thteshold[{error_threshold}] - {round((len(list_below)/len(predictions))*100,2)}%     {len(list_below)} izotermy na {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0911aa-a9e6-4ea2-99e4-77f0042be0c6",
   "metadata": {},
   "source": [
    "- skaler: \n",
    "    max error: [104.72827148]  dla Data156 1 K1  \n",
    "    for error thteshold[30] - 33.33%     6 izotermy na 18\n",
    "\n",
    "- log:\n",
    "    max error: [185.28442383]  dla Data79 2 0.25-C  \n",
    "    for error thteshold[30] - 100.0%     18 izotermy na 18\n",
    "- zwykly:\n",
    "max error: [246.68322754]  dla Data156 1 K1  \n",
    "for error thteshold[30] - 22.22%     4 izotermy na 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e6074adf-944c-4f5d-8df2-833d44909594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14    <---->  nan   \n",
      "-0.77    <---->  nan   \n",
      "-1.57    <---->  nan   \n",
      "-1.50    <---->  nan   \n",
      "-1.48    <---->  nan   \n",
      "-1.44    <---->  nan   \n",
      "-1.47    <---->  nan   \n",
      "-0.88    <---->  nan   \n",
      "0.26    <---->  nan   \n",
      "0.20    <---->  nan   \n",
      "1.38    <---->  nan   \n",
      "-0.54    <---->  nan   \n",
      "0.21    <---->  nan   \n",
      "1.09    <---->  nan   \n",
      "0.03    <---->  nan   \n",
      "1.04    <---->  nan   \n",
      "0.57    <---->  nan   \n",
      "-0.39    <---->  nan   \n",
      "-0.16    <---->  nan   \n",
      "-0.96    <---->  nan   \n",
      "-0.26    <---->  nan   \n",
      "1.66    <---->  nan   \n",
      "-0.87    <---->  nan   \n",
      "-0.29    <---->  nan   \n",
      "-0.23    <---->  nan   \n",
      "0.03    <---->  nan   \n",
      "0.01    <---->  nan   \n",
      "-0.24    <---->  nan   \n",
      "0.10    <---->  nan   \n",
      "0.12    <---->  nan   \n",
      "2.74    <---->  nan   \n",
      "2.21    <---->  nan   \n",
      "1.82    <---->  nan   \n",
      "0.96    <---->  nan   \n",
      "-0.50    <---->  nan   \n",
      "0.17    <---->  nan   \n",
      "1.15    <---->  nan   \n",
      "1.16    <---->  nan   \n",
      "-0.87    <---->  nan   \n",
      "-0.65    <---->  nan   \n",
      "0.07    <---->  nan   \n",
      "0.55    <---->  nan   \n",
      "1.93    <---->  nan   \n",
      "-1.25    <---->  nan   \n",
      "-0.21    <---->  nan   \n",
      "-1.61    <---->  nan   \n",
      "0.91    <---->  nan   \n",
      "1.32    <---->  nan   \n",
      "-1.78    <---->  nan   \n",
      "-0.59    <---->  nan   \n",
      "0.17    <---->  nan   \n",
      "2.14    <---->  nan   \n",
      "-1.37    <---->  nan   \n",
      "1.07    <---->  nan   \n",
      "1.31    <---->  nan   \n",
      "-0.11    <---->  nan   \n",
      "0.32    <---->  nan   \n",
      "0.35    <---->  nan   \n",
      "-0.03    <---->  nan   \n",
      "0.33    <---->  nan   \n",
      "0.88    <---->  nan   \n",
      "0.94    <---->  nan   \n",
      "-0.48    <---->  nan   \n",
      "-0.31    <---->  nan   \n",
      "0.29    <---->  nan   \n",
      "0.77    <---->  nan   \n",
      "1.10    <---->  nan   \n",
      "0.01    <---->  nan   \n",
      "-1.55    <---->  nan   \n",
      "0.09    <---->  nan   \n",
      "0.76    <---->  nan   \n",
      "-0.35    <---->  nan   \n",
      "0.11    <---->  nan   \n",
      "-0.55    <---->  nan   \n",
      "-0.03    <---->  nan   \n",
      "0.46    <---->  nan   \n",
      "-0.40    <---->  nan   \n",
      "0.25    <---->  nan   \n",
      "0.71    <---->  nan   \n",
      "1.03    <---->  nan   \n",
      "0.59    <---->  nan   \n",
      "-0.06    <---->  nan   \n",
      "0.08    <---->  nan   \n"
     ]
    }
   ],
   "source": [
    "predictions_for_data_without = model.predict(X_without, verbose=0)\n",
    "for i in range(len(predictions_for_data_without)):\n",
    "    print(f'{predictions_for_data_without[i][0]:.2f}    <---->  {y_without[i]:.2f}   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fde630-f090-450d-8207-1cc80eb4b62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc5ec9-e537-4f6d-9038-5d17153a365b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20223f01-8974-4a9f-8080-8657a833c097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4aa2279d-dccc-4867-be53-34df7c62e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"saved_models/model_s35_500_mae3400_maxerr-121_warstwy-35-160-50.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c5444ad-ab33-4bb7-b4ee-4cfdf705f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 18\n",
      "\n",
      "ALL:\n",
      " przewidywana --> [971.2737]     1041.9 <-- rzeczyswista     blad: [70.62631836]  ['Data58', '850-45m', '5_4', 'II']\n",
      " przewidywana --> [395.97638]     378.0 <-- rzeczyswista     blad: [17.97637939]  ['Data115', 'CAC1900', '1', 'I']\n",
      " przewidywana --> [742.24585]     770.1 <-- rzeczyswista     blad: [27.85415039]  ['Data58', '800-1h', '5_3', 'II']\n",
      " przewidywana --> [1362.1091]     1343.0 <-- rzeczyswista     blad: [19.10913086]  ['Data150', '10stC', '4', 'I_II']\n",
      " przewidywana --> [590.9509]     659.0 <-- rzeczyswista     blad: [68.04907227]  ['Data7', 'RK-600', '3', 'I']\n",
      " przewidywana --> [776.3707]     817.2 <-- rzeczyswista     blad: [40.82927246]  ['Data58', '800-1h15m', '5_3', 'II']\n",
      " przewidywana --> [1479.6089]     1387.0 <-- rzeczyswista     blad: [92.60888672]  ['Data65', 'R2-500', '2_2', 'I_IV']\n",
      " przewidywana --> [2005.0792]     2064.0 <-- rzeczyswista     blad: [58.92077637]  ['Data59', 'CMS500', '2', 'I_II']\n",
      " przewidywana --> [457.05875]     448.0 <-- rzeczyswista     blad: [9.05874634]  ['Data43', 'F1-8-11', '6', 'I']\n",
      " przewidywana --> [1829.2944]     1784.0 <-- rzeczyswista     blad: [45.29443359]  ['Data27', 'KUA21701-2', '1', 'I']\n",
      " przewidywana --> [1358.1982]     1305.0 <-- rzeczyswista     blad: [53.19824219]  ['Data27', 'KUA21701-200', '1', 'I']\n",
      " przewidywana --> [76.68123]     80.8 <-- rzeczyswista     blad: [4.11877136]  ['Data48', '2', '1_1', 'II']\n",
      " przewidywana --> [797.52]     864.0 <-- rzeczyswista     blad: [66.47998047]  ['Data61', 'CB', '1', 'I_II']\n",
      " przewidywana --> [1001.9593]     976.2 <-- rzeczyswista     blad: [25.75928955]  ['Data43', 'F2-66', '8', 'I']\n",
      " przewidywana --> [545.29584]     620.0 <-- rzeczyswista     blad: [74.7041626]  ['Data79', '0.25-C', '2', nan]\n",
      " przewidywana --> [1178.1295]     1165.8 <-- rzeczyswista     blad: [12.3295166]  ['Data91', 'AC-Gly', '3_1', 'I']\n",
      " przewidywana --> [1540.8043]     1426.0 <-- rzeczyswista     blad: [114.80432129]  ['Data156', 'K1', '1', 'I']\n",
      " przewidywana --> [450.83722]     400.0 <-- rzeczyswista     blad: [50.83721924]  ['Data119', 'Xp0.50', '6', 'IV']\n",
      "max error: [114.80432129]  dla ['Data156', 'K1', '1', 'I'] \n",
      "for error thteshold[30] - 38.89%     7 izotermy na 18\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_name = 'saved_models/model_s35_500_mae34_maxerr-121_warstwy-35-160-50.keras'\n",
    "modelos = load_model(model_name)\n",
    "predictions = modelos.predict(X_test, verbose=0)\n",
    "print(f\"len {len(X_test)}\")\n",
    "error_threshold = 30\n",
    "max_error_threshold = 30\n",
    "list_below =[]\n",
    "list_above=[]\n",
    "errors = []\n",
    "for i in range(len(predictions)):\n",
    "    errors.append(abs(predictions[i] - y_test[i]))\n",
    "    # print(f\"{i} {predictions[i]}  ------   {y_valid[i]}           blad: {abs(predictions[i] - y_valid[i])}\")\n",
    "    # if(abs(predictions[i] - y_test[i]) > max_error_threshold):\n",
    "    #     print(f\" przewidywana --> {predictions[i]}     {y_test[i]} <-- rzeczyswista     blad: {abs(predictions[i] - y_test[i])}  {y_test_nested[i][1]}\")\n",
    "        \n",
    "    if(error_threshold<=abs(predictions[i] - y_test[i])):\n",
    "        list_above.append(i)\n",
    "    else: list_below.append(i)\n",
    "print(\"\\nALL:\")\n",
    "for i in range(len(predictions)):\n",
    "    print(f\" przewidywana --> {predictions[i]}     {y_test[i]} <-- rzeczyswista     blad: {abs(predictions[i] - y_test[i])}  {y_test_nested[i][1]}\")\n",
    "        \n",
    "\n",
    "\n",
    "print(f\"max error: {max(errors)}  dla {y_test_nested[errors.index(max(errors))][1]} \" )\n",
    "print(f\"for error thteshold[{error_threshold}] - {round((len(list_below)/len(predictions))*100,2)}%     {len(list_below)} izotermy na {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9c21f-6875-43b4-be14-4915501910cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  przewidywana --> [553.189]     249.0 <-- rzeczyswista     blad: [304.18903]  ['Data125', 'coconut_shells_6h', '7']\n",
    "#  przewidywana --> [1967.7969]     1616.22 <-- rzeczyswista     blad: [351.5769]  ['Data153', 'GC-C04', '4']\n",
    "#  przewidywana --> [1556.715]     1193.2 <-- rzeczyswista     blad: [363.515]  ['Data54', 'CZ0.65', '3']\n",
    "#  przewidywana --> [1296.133]     938.0 <-- rzeczyswista     blad: [358.13306]  ['Data15', '3', '1']\n",
    "#  przewidywana --> [732.7655]     1188.0 <-- rzeczyswista     blad: [455.2345]  ['Data156', 'MCAC-2-1', '4']\n",
    "#  przewidywana --> [573.38586]     976.0 <-- rzeczyswista     blad: [402.61414]  ['Data47', 'ACF30M-HNO3', '3']\n",
    "#  przewidywana --> [350.85513]     823.0 <-- rzeczyswista     blad: [472.14487]  ['Data86', 'ACZ3', '2']\n",
    "# max error: [472.14487]  dla ['Data86', 'ACZ3', '2'] \n",
    "# for error thteshold[50] - 57.8%     100 izotermy na 173"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
